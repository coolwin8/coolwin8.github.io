{"meta":{"title":"CoolWin8的技术博客","subtitle":"Notes","description":"coolwin8的日常技术笔记","author":"lengwei","url":"http://coolwin8.github.io","root":"/"},"pages":[{"title":"categories","date":"2020-04-11T12:19:56.000Z","updated":"2020-04-11T04:20:26.880Z","comments":true,"path":"categories/index.html","permalink":"http://coolwin8.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Gitlab配置管理和使用","slug":"Gitlab配置管理和使用","date":"2020-04-18T13:52:17.000Z","updated":"2020-04-18T06:08:43.056Z","comments":true,"path":"2020/04/18/Gitlab配置管理和使用/","link":"","permalink":"http://coolwin8.github.io/2020/04/18/Gitlab%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86%E5%92%8C%E4%BD%BF%E7%94%A8/","excerpt":"","text":"1、公司gitlab服务内外网访问 内网访问 docker部署 gitlab 172.16.252.81:9080 外网访问 通过frp和阿里云主机，进行反向代理实现外网访问 2、访问方法 http方式 12# 替换自己的用户名、口令，指定端口号（因docker方式部署开放9080，页面上http不显示端口号）git clone http:&#x2F;&#x2F;用户名:口令@172.16.252.81:9080&#x2F;lw&#x2F;wis-actuator.git ssh方式 首先生成本机ssh秘钥 12ssh-keygen -t rsacat ~&#x2F;.ssh&#x2F;id_rsa.pub 然后web登陆gitlab，进入 “我的”–&gt; “设置”–&gt; “SSH秘钥”,将上面的密钥串复制到下图文本框中 免密访问gitlab 12# ssh 可以实现免密访问，docker部署开放ssh端口号为9022git clone ssh:&#x2F;&#x2F;git@172.16.252.81:9022&#x2F;lw&#x2F;wis-actuator.git","categories":[{"name":"配置管理","slug":"配置管理","permalink":"http://coolwin8.github.io/categories/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"},{"name":"版本管理","slug":"配置管理/版本管理","permalink":"http://coolwin8.github.io/categories/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://coolwin8.github.io/tags/gitlab/"},{"name":"配置管理","slug":"配置管理","permalink":"http://coolwin8.github.io/tags/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"}]},{"title":"SpringBoot+Maven多模块项目构建完整流程","slug":"SpringBoot-Maven多模块项目构建完整流程","date":"2020-04-14T12:44:42.000Z","updated":"2020-04-14T05:11:57.854Z","comments":true,"path":"2020/04/14/SpringBoot-Maven多模块项目构建完整流程/","link":"","permalink":"http://coolwin8.github.io/2020/04/14/SpringBoot-Maven%E5%A4%9A%E6%A8%A1%E5%9D%97%E9%A1%B9%E7%9B%AE%E6%9E%84%E5%BB%BA%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B/","excerpt":"","text":"开发环境：IDEA， SprngBoot 2.0.4， Maven 2.19.1工程结构： 父工程father 子模块 dao （用于持久化数据跟数据库交互） 子模块 entity （实体类） 子模块 service （处理业务逻辑） 子模块 web （页面交互接收、传递数据，唯一有启动类的模块） 关系： web依赖 service、dao、entity service依赖 dao、entity dao依赖 entity entity谁都不依赖，独立的 这里我用比较常见的工程结构举例说明，有些公司的项目可能会把模块分的很细，或者会有两个程序入口，也就是两个可以启动的模块！这个我在文章最后会做说明！缕清了思路其实没那么复杂！ 一，创建Maven多模块项目先建立外层父工程 File →new →project 选择Spring Initializr Next下一步到以下页面 工程结构如下 接下来，把src整个删掉，父工程不需要，因为父工程你就当它只有一个外壳就完了。 然后创建子模块 工程上右键 → new → Module 选择Spring Initaializr 下一步 重复以上动作，创建dao模块，service模块，web模块 service模块和entity模块一样什么都不需要引入 dao模块和web模块可以根据实际需求选择引入mysql，mybatis，redis，web这些，我把我的贴出来 删除每个子模块中没用的文件，.mvn、.gitignore、mvnw、mvnw.cmd文件只留下pom.xml 删除除了web模块以外其它模块中的Applicatin启动项，和resources目录下的application.properties配置文件 以上动作操作完成以后如果你发现你的子模块变成了文件夹，没关系，找到Maven Projects刷新一下就好了 整理过后的项目结构是这样的 以上项目的基本结构就完成了，接下来建立各自依赖 二、依赖关系打开父pom.xml修改打包方式jar为pom，注意：build内容也需要做替换，因为默认的spring-boot-maven-plugin这种方式，等到后期打包的时候他会一直提示你，你引入的依赖不存在！ 父pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--父pom.xml--&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;father&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;father&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;!--声明你有四个儿子 --&gt; &lt;modules&gt; &lt;module&gt;entity&lt;/module&gt; &lt;module&gt;dao&lt;/module&gt; &lt;module&gt;service&lt;/module&gt; &lt;module&gt;web&lt;/module&gt; &lt;/modules&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;java.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java.version&#125;&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.19.1&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;!--默认关掉单元测试 --&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 这里有个坑需要注意，dao、service、entity这三个模块的pom.xml文件中不需要build 内容，直接干掉 entity 的 pom.xml 内容 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;entity&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;entity&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;!--声明父模块--&gt; &lt;parent&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;father&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; dao 的 pom.xml 内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--dao 模块 pom.xml--&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;dao&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;dao&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;!--声明父模块--&gt; &lt;parent&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;father&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--dao 模块 引入entity模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;entity&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; service 模块的 pom.xml 内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;service&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;!--声明父模块--&gt; &lt;parent&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;father&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--service模块 引入entity模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;entity&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--service模块 引入dao模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;dao&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; web模块的 pom.xml 内容 注意build部分，因为web模块作为程序的入口启动，所以它需要打包，并且要指定Main Class 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;web&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;web&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;!--声明父模块--&gt; &lt;parent&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;father&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--web模块 引入entity模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;entity&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--web模块 引入service模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;service&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--web模块 引入dao模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.miu&lt;/groupId&gt; &lt;artifactId&gt;dao&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 指定该Main Class为全局的唯一入口 --&gt; &lt;mainClass&gt;com.miu.web.WebApplication&lt;/mainClass&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt;&lt;!--可以把依赖的包都打包到生成的Jar包中--&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 到此为止所有的依赖全部完成！接下来就是测试！这里只用简单的测试来实验！ 三、代码测试entity模块中创建 EntiyTest类 dao模块中创建 DaoTest类 service模块中创建ServiceTest类 Web模块中创建WebTest类 最后把web模块中的application.properties文件补充一下就OK了，因为引入了mysql，redis等配置，所以数据源是要配的，不然运行起来会报错找不到数据源！ 12345678910111213141516server.port=8080#-----------------------------------数据库配置----------------------------------------spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://127.0.0.1:3306/test?characterEncoding=utf8spring.datasource.username=rootspring.datasource.password=123#------------------------------------redis配置---------------------------------------spring.redis.database=0spring.redis.host=127.0.0.1spring.redis.port=6379spring.redis.password=spring.redis.jedis.pool.max-active=8spring.redis.jedis.pool.max-idle=8spring.redis.jedis.pool.max-wait=-1msspring.redis.jedis.pool.min-idle=0spring.redis.timeout=10000ms 一切准备就绪，开始运行web模块下的启动类进行测试 四、打包可执行jar 看到上面的页面就证明模块之间的依赖没有问题，调用正常，我这里是用简单的创建对象的这种方式来操作的，实际开发并不是这种操作，大部分都是通过 @Autowired 注解 来实现的注入，这里我就不做演示了，只要模块之间调用没问题，剩下的就是铺代码的事了，接下来还有最后一个打包问题，为什么要啰嗦那么多还要说打包问题呢，因为我建议在项目架构之初，除了搭框架以外，最好是在最开始的时候就测试一下打包，尤其是这种多模块项目之间各种依赖的这种工程的打包，如果等你代码写的铺天盖地的时候你在去想怎么打包，到时候有你头疼的！如果你是按照我本章的流程一步步下来的话，那么你完全不用担心打包问题，因为所有的pom.xml有已经配置好了，只需要动手运行 package打包动作就行了，第一次打包不需要clean，记住以后每次打包之前clean一下，关于为什么打jar包，不打war包这个问题，还有其它会遇到的问题，在文章最后会做说明！ 双击运行package，看到BUILD SUCCESS 就证明打包成功了，如此简单？告诉你就是这么简单，前提是你的每一个模块下的pom.xml要配置好，谁需要打包，谁不需要打包，谁依赖谁，父工程是否声明了子模块，子模块是否声明了父工程是谁，这些是重点！ 接下来去找你工程目录，web文件夹下的target文件夹，刚才打包好的jar文件，就放在这里了 然后我把这个jar文件上传到我的测试服务器，使用 java -jar web-0.0.1-SNAPSHOT.jar 命令来测试运行打包的可执行jar文件到底行不行！ 运行成功，输入我测试服务器地址测试也没问题，到此为止全部搞定 聚合工程举一个简单的例子， 整个工程你就当作一个公司，父工程（退休了什么也不干）只需要声明有几个儿子（子模块）就完事了， 子模块web声明父工程是谁，就当他是大儿子，公司他管事，pom.xml文件需要打包，需要build配置，需要其它三个兄弟帮助 其它子模块声明父工程是谁，之间关系都是兄弟，不需要打包，哪里需要去哪里！ 在此我说一下重点和需要注意的地方！1.父pom.xml 打包方式，jar要更改为pom，build 需要更改 2.不需要打包的模块pom.xml文件中不要写，全删掉，例如有些工程中的common模块，utils模块，entity模块，service模 块都不需要打包 3.声明父工程时，填写父工程位置../pom.xml 4.关于applicatin.properties配置文件，只需要在启动的模块中配置就可以了， 5.关于打包为什么打包jar包，不打war包，打war包目的是war包可以运行在tomcat下，但是SpringBoot是内置tomcat，如果你打war包，前提是干掉内置的tomcat，然后才能打包，各种麻烦，直接打包可执行jar包，使用java -jar 命令就可以完美的运行起来很方便！ 6.真实开发中使用@Autowired 注解 来实现注入，而不是new对象这种方式，所以可能会产生注入以后报错，是因为你的启动类上没有配置扫描，使用@ComponentScan(basePackages = “你的路径”)注解来解决，如果你使用的持久层是Mybatis，那么你的mapper也需要扫描，在启动类上使用@MapperScan(“你的mapper文件地址”)注解来解决，算了还是贴个图片吧 不罗嗦了，就到这里吧，一个文章写了两个小时可见我的良苦用心，（关键是我被这个多模块打包问题困扰了好长时间，网上各种找解决办法，说的天花乱坠，狗屁不通，服的五体投地）————————————————版权声明：本文为CSDN博主「凌云冷海」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/baidu_41885330/article/details/81875395","categories":[{"name":"Java生态","slug":"Java生态","permalink":"http://coolwin8.github.io/categories/Java%E7%94%9F%E6%80%81/"},{"name":"SprintBoot","slug":"Java生态/SprintBoot","permalink":"http://coolwin8.github.io/categories/Java%E7%94%9F%E6%80%81/SprintBoot/"}],"tags":[{"name":"多模块","slug":"多模块","permalink":"http://coolwin8.github.io/tags/%E5%A4%9A%E6%A8%A1%E5%9D%97/"},{"name":"maven","slug":"maven","permalink":"http://coolwin8.github.io/tags/maven/"}]},{"title":"利用softEther VPN远程访问内部网络","slug":"利用softEther VPN远程访问内部网络","date":"2020-04-14T12:39:53.000Z","updated":"2020-04-13T16:10:49.215Z","comments":true,"path":"2020/04/14/利用softEther VPN远程访问内部网络/","link":"","permalink":"http://coolwin8.github.io/2020/04/14/%E5%88%A9%E7%94%A8softEther%20VPN%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE%E5%86%85%E9%83%A8%E7%BD%91%E7%BB%9C/","excerpt":"","text":"利用 softEther VPN 进行远程访问1作者: whr 使用场景和前提条件 内部网络受到保护，无法直接在内部网络中的主机中直接部署VPN server（搭建完无法连接到该server） 用户需要从外部网络远程访问内部网络中的资源，如主机或打印机等等 对内部网络中的某台主机拥有管理权限 有一台暴露在互联网中的主机 内部网络中的主机可以直接访问互联网 比如 学生于校外访问校园网资源 远程办公 管理家庭局域网设备 举个栗子这里通过一个例子，描述如何通过一步步的操作，利用softEther VPN 套件实现远程访问。 一个安全的网络（192.168.1.0/24），它受到防火墙和NAT的保护，无法从Internet访问，但是可以通过防火墙或NAT代理访问Internet上的网站。该网络中， IP地址为 192.168.1.111 的一台打印机，IP地址为 192.186.1.222 的一台主机H。一台暴露在Internet的主机S，IP地址为 125.111.111.111。 目标 通过构建主机S和主机H所在内部网络的级联网络，用户可以通过连接主机S所创建的VPN，实现对内部网络（192.168.1.0/24）中的资源的访问。 开始你的表演总体上整个任务的关键位置所运行的SoftEther VPN组件如下图所示 1、在主机S上安装搭建VPN server连接到 主机S ，将SoftEther VPN Server 组件下载到本地。组件选择地址根据实际运行环境，选择适当的版本。这里我选择的是Linux 系统，CPU选择的是Intel x64 / AMD64 (64bit)。 拿到下载地址后，使用wget命令进行下载，： 12345678# 下载softether-vpnserver到本地wget https:&#x2F;&#x2F;github.com&#x2F;SoftEtherVPN&#x2F;SoftEtherVPN_Stable&#x2F;releases&#x2F;download&#x2F;v4.30-9696-beta&#x2F;softether-vpnserver-v4.30-9696-beta-2019.07.08-linux-x64-64bit.tar.gz#解压tar zxvf softether-*server*.tar.gzcd vpnserver&#x2F;# 这里面有一个隐藏的文件.install.sh，运行它。[vpnserver]# .&#x2F;.install.sh# 一路Yes，Agree默认即可 查看下载的文件进入对应文件夹运行安装脚本进行默认配置 安装完成后进入 1234567891011121314151617181920212223242526272829# 启动vpnserver[vpnserver]# .&#x2F;vpnserver start# 进行vpn的初始配置[vpnserver]# .&#x2F; vpncmdBy using vpncmd program, the following can be achieved.1. Management of VPN Server or VPN Bridge2. Management of VPN Client3. Use of VPN Tools (certificate creation and Network Traffic Speed Test Tool)Select 1, 2 or 3:# 选择1 回车Hostname of IP Address of Destination:# 回车If connecting to the server by Virtual Hub Admin Mode, please input the Virtual Hub name.If connecting by server admin mode, please press Enter without inputting anything.Specify Virtual Hub Name:# 回车Password:# 回车VPN Server&gt;ServerPasswordSet# 输入 ServerPasswordSetServerPasswordSet command - Set VPN Server Administrator PasswordPlease enter the password. To cancel press the Ctrl+D key.# 设置你的服务器管理密码Password: ******#这里输入管理密码Confirm input: ******#确认密码 至此，主机S上的vpnserver的安装和初步的配置就完成了，后面将介绍使用SoftEther VPN Server Manager 对其进行进一步的配置。 2、在主机H上安装搭建VPN Bridge连接到 主机H ，将SoftEther VPN Bridge 组件下载到本地。这里就不贴图了，具体和下载vpnserver一样，换成vpnbridge。下载地址 根据实际运行环境，选择适当的版本。这里我选择的是Linux 系统，CPU选择的是Intel x64 / AMD64 (64bit)。使用wget 命令进行下载，安装，初步配置也都相近： 12345678910111213141516171819202122232425262728293031323334353637383940# 下载softether-vpnbridge到本地wget https:&#x2F;&#x2F;github.com&#x2F;SoftEtherVPN&#x2F;SoftEtherVPN_Stable&#x2F;releases&#x2F;download&#x2F;v4.30-9696-beta&#x2F;softether-vpnbridge-v4.30-9696-beta-2019.07.08-linux-x64-64bit.tar.gz#解压tar zxvf softether-*bridge*.tar.gzcd vpnserver&#x2F;# 这里面有一个隐藏的文件.install.sh，运行它。[vpnbridge]# .&#x2F;.install.sh# 一路Yes，Agree默认即可[vpnbridge]# .&#x2F;vpnbridge start[vpnbridge]# .&#x2F;vpncmd...By using vpncmd program, the following can be achieved.1. Management of VPN Server or VPN Bridge2. Management of VPN Client3. Use of VPN Tools (certificate creation and Network Traffic Speed Test Tool)Select 1, 2 or 3: 1# 输入1Specify the host name or IP address of the computer that the destination VPN Server or VPN Bridge is operating on.By specifying according to the format &#39;host name:port number&#39;, you can also specify the port number.(When the port number is unspecified, 443 is used.)If nothing is input and the Enter key is pressed, the connection will be made to the port number 8888 of localhost (this computer).Hostname of IP Address of Destination:#回车If connecting to the server by Virtual Hub Admin Mode, please input the Virtual Hub name.If connecting by server admin mode, please press Enter without inputting anything.Specify Virtual Hub Name:#回车Connection has been established with VPN Server &quot;localhost&quot; (port 443).You have administrator privileges for the entire VPN Server.VPN Server&gt;ServerPasswordSetServerPasswordSet command - Set VPN Server Administrator PasswordPlease enter the password. To cancel press the Ctrl+D key.Password: ******#这里输入管理密码Confirm input: ******#确认密码The command completed successfully. 3、配置主机S上的vpnserver这里需要找了一台windows的机子，因为SoftEther提供了一款SoftEther VPN Server Manager的图形管理器，进行蛇者比较方便。要求就是最好在内网中，方便连接主机H，同时也能连接主机S。将SoftEther VPN Server Manager for Windows 图形组件下载到本地。下载地址 运行SoftEther VPN Server Manager，点击设置 填入设置名（这个随意），主机名填入主机S的IP地址，端口采用默认的443，代理类型选择直接TCP/IP连接（无代理），选中服务端管理模式并填入前面设置的vpnserver管理密码，点击确定。如果你在前面没有设置管理密码，在连接的时候将也提示你设置密码。 勾选远程访问VPN Server (R)，点击下一步后提示确认初始化，选择 是。 为你的vpnserver设置一个名字，这里输入VPN，点击确定。 动态DNS功能，不用管，直接无视选择退出。 IPsec/L2TP 设置，勾选启用L2TP服务器功能，并设置IPsec预共享秘钥。这一步是为了后面我们可以用手机或者PC自带的VPN工具进行连接。 VPN Azure 云，勾选禁用，点击确定。 创建一个用户来接受VPN连接，点击创建用户。 填入相关信息，验证类型选择密码验证，并在密码验证设置中填入密码。 我们这里需要创建两个账号，分别为user1和user2，一个用于主机H上的VPN bridge，一个用于用户在外网的状态下登录VPN。 点击关闭进入下一步。 点击管理HUB。 点击虚拟NAT和虚拟DHCP服务器。 点击启用SecureNAT，这一步很关键。 确定启用SecureNAT。 点击关闭。 至此，我们对于主机S上的VPN server的配置就完成了，接下来连接到主机H上的vpn bridge进行配置。 4、配置主机H上的vpnbridge同样是回到SoftEther VPN Server Manager主界面，点击新设置，填入VPN bridge的IP地址，这里是 192.168.1.222，如果前面在初步配置的时候选择默认的话，端口选择5555，如果前面在初步配置的时候选择默认的话。并填入管理密码。（参考3-1,3-2） 勾选站到站 VPN Server 或 VPN Bridge，选择下一步。 设置本地网桥。这里如果你有多张网卡的话，要选择你想级联出去网段所在的网卡。这里我想级联192.168.1.0/24网段，我选择配置为该网段地址的网卡，eth0。不清楚对应网卡的可以在控制台运行ifconfig命令查看。 回到管理器面板，点击管理虚拟HUB，点击虚拟NAT和虚拟DHCP服务器，启用 SecureNAT。 回到管理器面板，点击管理虚拟HUB，选择管理级联连接。 填写连接设置名(自由设置)，填写vpnserver的地址，即主机S的IP地址，端口号选择443。只要你的地址和端口填写正确，并且前面配置无误，这里虚拟HUB名的下拉列表就能找到我们之前创建的虚拟HUB “VPN”。勾选无代理，选择认证类型为标准密码验证，并填写用户名密码。这里使用创建的用户user1。点击确定。 进入到级联管理界面，选中我们刚刚创建的连接，点击在线。 发现该装填已由离线变成在线。 至此，我们在对主机H的vpn bridge的配置也大功告成。此时主机S与主机H逻辑上已经是同属一个网络，主机S可以直接访问内网192.168.1.0/24网络。所以下一步，我们只要连接到主机S的VPN，我们也就可以和主机S一样，直接访问内网192.168.1.0/24网络的资源了。 5. 用户配置L2TP/IPsec VPN IOS端设置。 Android端设置。 ————————————————连接时填入用户名密码即可。 Windows端设置。 连接有问题的时候请检查一下主机S的防火墙和安全策略设置。请开启L2TP必要的端口：UDP 500、4500、1701。 完结撒花最后更新： 2019年11月03日 09:51 原始链接： https://silence-linhl.github.io/blog/2019/11/02/softEther/ Harlan","categories":[{"name":"系统应用 网络应用","slug":"系统应用-网络应用","permalink":"http://coolwin8.github.io/categories/%E7%B3%BB%E7%BB%9F%E5%BA%94%E7%94%A8-%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"网络配置","slug":"网络配置","permalink":"http://coolwin8.github.io/tags/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"name":"VPN","slug":"VPN","permalink":"http://coolwin8.github.io/tags/VPN/"},{"name":"内网访问","slug":"内网访问","permalink":"http://coolwin8.github.io/tags/%E5%86%85%E7%BD%91%E8%AE%BF%E9%97%AE/"}]},{"title":"github配置ssh-key访问","slug":"github配置ssh-key访问","date":"2020-04-14T09:52:17.000Z","updated":"2020-04-14T01:53:22.074Z","comments":true,"path":"2020/04/14/github配置ssh-key访问/","link":"","permalink":"http://coolwin8.github.io/2020/04/14/github%E9%85%8D%E7%BD%AEssh-key%E8%AE%BF%E9%97%AE/","excerpt":"","text":"配置SSH Key到GitHub1.生成SSH Key在Linux和Mac系统中都自动安装了SSH，Windows系统需要安装Git Bash。 首先检查下本机是否已经安装了SSH，在终端输入ssh即可： 接下来就是生成ssh key了，输入ssh-keygen -t rsa，然后连续按回车键三次（如果输入密码，每次登陆都需要密码）。 出现上面内容就说明成功生成id_rsa和id_rsa.pub两个文件，id_rsa.pub为公钥，id_rsa为私钥，它们都是隐藏文件。这里说明下生成的公钥和私钥所在位置，Linux和Mac系统在 下面，Windows系统在C盘Documents and Settings/username/.ssh下面。 那么如何查看它们的内容呢？只需要继续执行以下两条命令即可。 可以看到，执行完ls命令后，可以看到公钥和私钥。继续执行以下命令（此处为Linux和Mac系统下获取公钥内容，下面会用到公钥）即可得到公钥的内容： 12cat id_rsa.pub复制代码 Windows系统查看公钥可以使用Sublime或者其他编辑器。 2.添加SSH Key到GitHub上这里需要将公钥id_rsa.pub添加到GitHub上，登陆GitHub进入设置界面，如图所示： 接着执行下面操作： 点击New SSH Key按钮后进行Key的填写操作，完成SSH Key的添加。添加SSH Key成功之后，继续输入命令进行测试。 12ssh -T git@github.com复制代码 出现以上截图，说明配置成功！","categories":[{"name":"GitHub","slug":"GitHub","permalink":"http://coolwin8.github.io/categories/GitHub/"}],"tags":[{"name":"配置管理","slug":"配置管理","permalink":"http://coolwin8.github.io/tags/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"},{"name":"SSH","slug":"SSH","permalink":"http://coolwin8.github.io/tags/SSH/"}]},{"title":"kubeclt 备忘单","slug":"kubectl-备忘单","date":"2020-04-14T09:42:04.000Z","updated":"2020-04-14T01:44:34.362Z","comments":true,"path":"2020/04/14/kubectl-备忘单/","link":"","permalink":"http://coolwin8.github.io/2020/04/14/kubectl-%E5%A4%87%E5%BF%98%E5%8D%95/","excerpt":"","text":"本页面是 kubectl 命令的概述。 kubectl - 备忘单 Kubectl 自动补全 Kubectl 上下文和配置 Apply 创建对象 获取和查找资源 更新资源 局部更新资源 编辑资源 对资源进行伸缩 删除资源 与运行中的 Pods 进行交互 与节点和集群进行交互 接下来 kubectl - 备忘单Kubectl 自动补全BASH12source &lt;(kubectl completion bash) # 在 bash 中设置当前 shell 的自动补全，要先安装 bash-completion 包。echo \"source &lt;(kubectl completion bash)\" &gt;&gt; ~/.bashrc # 在您的 bash shell 中永久的添加自动补全 您还可以为 kubectl 使用一个速记别名，该别名也可以与 completion 一起使用： 12alias k=kubectlcomplete -F __start_kubectl k ZSH12source &lt;(kubectl completion zsh) # 在 zsh 中设置当前 shell 的自动补全echo \"if [ $commands[kubectl] ]; then source &lt;(kubectl completion zsh); fi\" &gt;&gt; ~/.zshrc # 在您的 zsh shell 中永久的添加自动补全 Kubectl 上下文和配置设置 kubectl 与哪个 Kubernetes 集群进行通信并修改配置信息。查看 使用 kubeconfig 跨集群授权访问 文档获取详情配置文件信息。 1234567891011121314151617kubectl config view # 显示合并的 kubeconfig 配置。# 同时使用多个 kubeconfig 文件并查看合并的配置KUBECONFIG=~/.kube/config:~/.kube/kubconfig2 kubectl config view# 获取 e2e 用户的密码kubectl config view -o jsonpath='&#123;.users[?(@.name == \"e2e\")].user.password&#125;'kubectl config current-context # 展示当前所处的上下文kubectl config use-context my-cluster-name # 设置默认的上下文为 my-cluster-name# 添加新的集群配置到 kubeconf 中，使用 basic auth 进行鉴权kubectl config set-credentials kubeuser/foo.kubernetes.com --username=kubeuser --password=kubepassword# 使用特定的用户名和命名空间设置上下文。kubectl config set-context gce --user=cluster-admin --namespace=foo \\ &amp;&amp; kubectl config use-context gce Applyapply 通过定义 Kubernetes 资源的文件管理应用程序。它通过运行 kubectl apply 在集群中创建和更新资源。这是在生产中管理 Kubernetes 应用程序的推荐方法。查阅 Kubectl 文档。 创建对象Kubernetes 配置可以用 json 或 yaml 定义。可以使用的文件扩展名有 .yaml，.yml 和 .json。 123456789101112131415161718192021222324252627282930313233343536373839404142434445kubectl apply -f ./my-manifest.yaml # 创建资源kubectl apply -f ./my1.yaml -f ./my2.yaml # 使用多个文件创建kubectl apply -f ./dir # 从目录下的全部配置文件创建资源kubectl apply -f https://git.io/vPieo # 从 url 中创建资源kubectl create deployment nginx --image=nginx # 启动单实例 nginxkubectl explain pods,svc # 获取 pod，svc 配置的文档说明# 从标准输入中的多个 YAML 对象中创建cat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Podmetadata: name: busybox-sleepspec: containers: - name: busybox image: busybox args: - sleep - \"1000000\"---apiVersion: v1kind: Podmetadata: name: busybox-sleep-lessspec: containers: - name: busybox image: busybox args: - sleep - \"1000\"EOF# 创建有多个 key 的 Secretcat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Secretmetadata: name: mysecrettype: Opaquedata: password: $(echo -n \"s33msi4\" | base64 -w0) username: $(echo -n \"jane\" | base64 -w0)EOF 获取和查找资源12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 使用 get 命令获取基本输出kubectl get services # 列出当前命名空间下的所有 serviceskubectl get pods --all-namespaces # 列出所有命名空间下的全部的 podskubectl get pods -o wide # 列出当前命名空间下的全部 pods，有更多的详细信息kubectl get deployment my-dep # 列出某个特定的 deploymentkubectl get pods --include-uninitialized # 列出当前命名空间下的全部 pods，包含未初始化的kubectl get pod my-pod -o yaml # 获取一个 pod 的 YAMLkubectl get pod my-pod -o yaml --export # 获取一个没有集群特定信息的 YAML# 使用 describe 命令获取详细输出kubectl describe nodes my-nodekubectl describe pods my-podkubectl get services --sort-by=.metadata.name # 列出当前命名空间下所有 services，按照名称排序# 列出 pods 按照重启次数进行排序kubectl get pods --sort-by='.status.containerStatuses[0].restartCount'# 列出测试命名空间中的 Pod，按容量排序kubectl get pods -n test --sort-by=.spec.capacity.storage # 获取包含 app=cassandra 标签全部 pods 的 version 标签kubectl get pods --selector=app=cassandra -o \\ jsonpath='&#123;.items[*].metadata.labels.version&#125;'# 获取所有工作节点(使用选择器以排除标签名称为 'node-role.kubernetes.io/master' 的结果)kubectl get node --selector='!node-role.kubernetes.io/master'# 获取当前命名空间中正在运行的 podskubectl get pods --field-selector=status.phase=Running# 获取全部 node 的 ExternalIP 地址kubectl get nodes -o jsonpath='&#123;.items[*].status.addresses[?(@.type==\"ExternalIP\")].address&#125;'# 列出属于某个特定 RC 的 pods 的名称# \"jq\" 命令对于 jsonpath 过于复杂的转换非常有用，可以在 https://stedolan.github.io/jq/ 找到它。sel=$&#123;$(kubectl get rc my-rc --output=json | jq -j '.spec.selector | to_entries | .[] | \"\\(.key)=\\(.value),\"')%?&#125;echo $(kubectl get pods --selector=$sel --output=jsonpath=&#123;.items..metadata.name&#125;)# 显示所有 Pod 的标签(或任何其他支持标签的 Kubernetes 对象)# 也可以使用 \"jq\"for item in $( kubectl get pod --output=name); do printf \"Labels for %s\\n\" \"$item\" | grep --color -E '[^/]+$' &amp;&amp; kubectl get \"$item\" --output=json | jq -r -S '.metadata.labels | to_entries | .[] | \" \\(.key)=\\(.value)\"' 2&gt;/dev/null; printf \"\\n\"; done# 或也可以使用此命令来获取与容器关联的所有标签kubectl get pods --show-labels# 检查哪些节点处于 readyJSONPATH='&#123;range .items[*]&#125;&#123;@.metadata.name&#125;:&#123;range @.status.conditions[*]&#125;&#123;@.type&#125;=&#123;@.status&#125;;&#123;end&#125;&#123;end&#125;' \\ &amp;&amp; kubectl get nodes -o jsonpath=\"$JSONPATH\" | grep \"Ready=True\"# 列出被一个 pod 使用的全部 secretkubectl get pods -o json | jq '.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name' | grep -v null | sort | uniq# 列出 events，按照创建时间排序kubectl get events --sort-by=.metadata.creationTimestamp 更新资源从版本 1.11 开始，rolling-update 已被弃用（参见 CHANGELOG-1.11.md)，请使用 rollout 代替。 1234567891011121314151617181920212223242526kubectl set image deployment/frontend www=image:v2 # 滚动更新 \"frontend\" deployment 的 \"www\" 容器镜像kubectl rollout history deployment/frontend # 检查部署的历史记录，包括版本 kubectl rollout undo deployment/frontend # 回滚到上次部署版本kubectl rollout undo deployment/frontend --to-revision=2 # 回滚到特定部署版本kubectl rollout status -w deployment/frontend # Watch \"frontend\" deployment 的滚动升级状态直到完成# 从 1.11 版本开始弃用kubectl rolling-update frontend-v1 -f frontend-v2.json # (弃用) 滚动升级 frontend-v1 的 podskubectl rolling-update frontend-v1 frontend-v2 --image=image:v2 # (弃用) 修改资源的名称并更新镜像kubectl rolling-update frontend --image=image:v2 # (弃用) 更新 frontend 的 pods 的镜像kubectl rolling-update frontend-v1 frontend-v2 --rollback # (弃用) 终止已经进行中的 rolloutcat pod.json | kubectl replace -f - # 通过传入到标准输入的 JSON 来替换 pod# 强制进行替换，会删除然后再创建资源，会导致服务不可用。kubectl replace --force -f ./pod.json# 为多副本的 nginx 创建服务，使用 80 端口提供服务，连接到容器的 8000 端口。kubectl expose rc nginx --port=80 --target-port=8000# 更新单容器 pod 的镜像标签到 v4kubectl get pod mypod -o yaml | sed 's/\\(image: myimage\\):.*$/\\1:v4/' | kubectl replace -f -kubectl label pods my-pod new-label=awesome # 添加标签kubectl annotate pods my-pod icon-url=http://goo.gl/XXBTWq # 添加注解kubectl autoscale deployment foo --min=2 --max=10 # 使 \"foo\" deployment 自动伸缩容 局部更新资源12345678910111213kubectl patch node k8s-node-1 -p '&#123;\"spec\":&#123;\"unschedulable\":true&#125;&#125;' # 部分更新 node#更新容器的镜像；spec.containers[*].name 是必须的。因为它是一个合并 key。kubectl patch pod valid-pod -p '&#123;\"spec\":&#123;\"containers\":[&#123;\"name\":\"kubernetes-serve-hostname\",\"image\":\"new image\"&#125;]&#125;&#125;'# 使用带位置数组的 json patch 更新容器的镜像kubectl patch pod valid-pod --type='json' -p='[&#123;\"op\": \"replace\", \"path\": \"/spec/containers/0/image\", \"value\":\"new image\"&#125;]'# 使用带位置数组的 json patch 禁用 deployment 的 livenessProbekubectl patch deployment valid-deployment --type json -p='[&#123;\"op\": \"remove\", \"path\": \"/spec/template/spec/containers/0/livenessProbe\"&#125;]'# 在带位置数组中添加元素 kubectl patch sa default --type='json' -p='[&#123;\"op\": \"add\", \"path\": \"/secrets/1\", \"value\": &#123;\"name\": \"whatever\" &#125; &#125;]' 编辑资源在编辑器中编辑任何 API 资源 12kubectl edit svc/docker-registry # 编辑名为 docker-registry 的 serviceKUBE_EDITOR=\"nano\" kubectl edit svc/docker-registry # 使用其他编辑器 对资源进行伸缩1234kubectl scale --replicas=3 rs/foo # 将名为 'foo' 的副本集伸缩到 3 副本kubectl scale --replicas=3 -f foo.yaml # 将在 \"foo.yaml\" 中的特定资源伸缩到 3 个副本kubectl scale --current-replicas=2 --replicas=3 deployment/mysql # 如果名为 mysql 的 deployment 的副本当前是 2，那么将它伸缩到 3kubectl scale --replicas=5 rc/foo rc/bar rc/baz # 伸缩多个 replication controllers 删除资源1234567kubectl delete -f ./pod.json # 删除在 pod.json 中指定的类型和名称的 podkubectl delete pod,service baz foo # 删除名称为 \"baz\" 和 \"foo\" 的 pod 和 servicekubectl delete pods,services -l name=myLabel # 删除包含 name=myLabel 标签的 pods 和 serviceskubectl delete pods,services -l name=myLabel --include-uninitialized # 删除包含 label name=myLabel 标签的 pods 和 services，包括未初始化的kubectl -n my-ns delete po,svc --all # 删除在 my-ns 命名空间中全部的 pods 和 services ，包括未初始化的# 删除所有与 pattern1 或 pattern2 匹配的 podkubectl get pods -n mynamespace --no-headers=true | awk '/pattern1|pattern2/&#123;print $1&#125;' | xargs kubectl delete -n mynamespace pod 与运行中的 Pods 进行交互123456789101112131415kubectl logs my-pod # 获取 pod 日志(标准输出)kubectl logs -l name=myLabel # 获取 pod label name=myLabel 日志(标准输出)kubectl logs my-pod --previous # 获取上个容器实例的 pod 日志(标准输出)kubectl logs my-pod -c my-container # 获取 pod 的容器日志 (标准输出, 多容器的场景)kubectl logs -l name=myLabel -c my-container # 获取 label name=myLabel pod 的容器日志 (标准输出, 多容器的场景)kubectl logs my-pod -c my-container --previous # 获取 pod 的上个容器实例日志 (标准输出, 多容器的场景)kubectl logs -f my-pod # 流式输出 pod 的日志 (标准输出)kubectl logs -f my-pod -c my-container # 流式输出 pod 容器的日志 (标准输出, 多容器的场景)kubectl logs -f -l name=myLabel --all-containers # 流式输出 label name=myLabel pod 的日志 (标准输出)kubectl run -i --tty busybox --image=busybox -- sh # 以交互式 shell 运行 podkubectl attach my-pod -i # 进入到一个运行中的容器中kubectl port-forward my-pod 5000:6000 # 在本地计算机上侦听端口 5000 并转发到 my-pod 上的端口 6000kubectl exec my-pod -- ls / # 在已有的 pod 中运行命令(单容器的场景)kubectl exec my-pod -c my-container -- ls / # 在已有的 pod 中运行命令(多容器的场景)kubectl top pod POD_NAME --containers # 显示给定 pod 和容器的监控数据 与节点和集群进行交互12345678910kubectl cordon my-node # 设置 my-node 节点为不可调度kubectl drain my-node # 对 my-node 节点进行驱逐操作，为节点维护做准备kubectl uncordon my-node # 设置 my-node 节点为可以调度kubectl top node my-node # 显示给定 node 的指标kubectl cluster-info # 显示 master 和 services 的地址kubectl cluster-info dump # 将当前集群状态输出到标准输出kubectl cluster-info dump --output-directory=/path/to/cluster-state # 将当前集群状态输出到 /path/to/cluster-state# 如果已存在具有该键和效果的污点，则其值将按指定替换kubectl taint nodes foo dedicated=special-user:NoSchedule 资源类型列出全部支持的资源类型和它们的简称, API group, 无论它们是否是 namespaced, Kind。 1kubectl api-resources 用于探索 API 资源的其他操作： 123456kubectl api-resources --namespaced=true # 所有在命名空间中的资源kubectl api-resources --namespaced=false # 所有不在命名空间中的资源kubectl api-resources -o name # 输出简单的所有资源（只是资源名称）kubectl api-resources -o wide # 具有扩展（又称 \"wide\"）输出的所有资源kubectl api-resources --verbs=list,get # 支持 \"list\" 和 \"get\" 请求动词的所有资源kubectl api-resources --api-group=extensions # \"extensions\" API 组中的所有资源 格式化输出要以特定格式将详细信息输出到终端窗口，可以将 -o 或 --output 参数添加到支持的 kubectl 命令。 输出格式 描述 -o=custom-columns= 使用逗号分隔的自定义列列表打印表格 -o=custom-columns-file= 使用 `` 文件中的自定义列模板打印表格 -o=json 输出 JSON 格式的 API 对象 `-o=jsonpath= 打印 jsonpath 表达式中定义的字段 -o=jsonpath-file= 在 `` 文件中打印由 jsonpath 表达式定义的字段。 -o=name 仅打印资源名称而不打印任何其他内容 -o=wide 使用任何其他信息以纯文本格式输出，对于 pod 来说，包含了节点名称 -o=yaml 输出 YAML 格式的 API 对象 Kubectl 日志输出详细程度和调试Kubectl 日志输出详细程度是通过 -v 或者 --v 来控制的，参数后跟了一个数字表示日志的级别。Kubernetes 通用的日志习惯和相关的日志级别在 这里 有相应的描述。 详细程度 描述 --v=0 通常对此有用，始终对运维人员可见。 --v=1 如果您不想要详细程度，则为合理的默认日志级别。 --v=2 有关服务的有用稳定状态信息以及可能与系统中的重大更改相关的重要日志消息。这是大多数系统的建议默认日志级别。 --v=3 有关更改的扩展信息。 --v=4 Debug 级别。 --v=6 显示请求的资源。 --v=7 显示 HTTP 请求头。 --v=8 显示 HTTP 请求内容。 --v=9 显示 HTTP 请求内容而不截断内容。 接下来 学习更多关于 kubectl 概述。 查看 kubectl 选项. 也可以查看 kubectl 使用约定 来理解如果在可以复用的脚本中使用它。 查看更多社区 kubectl 备忘单。","categories":[{"name":"k8s生态","slug":"k8s生态","permalink":"http://coolwin8.github.io/categories/k8s%E7%94%9F%E6%80%81/"},{"name":"k8s","slug":"k8s生态/k8s","permalink":"http://coolwin8.github.io/categories/k8s%E7%94%9F%E6%80%81/k8s/"}],"tags":[{"name":"kubectl","slug":"kubectl","permalink":"http://coolwin8.github.io/tags/kubectl/"},{"name":"命令参考","slug":"命令参考","permalink":"http://coolwin8.github.io/tags/%E5%91%BD%E4%BB%A4%E5%8F%82%E8%80%83/"}]},{"title":"docker下gitlab安装配置使用完整版","slug":"Docker下Gitlab安装配置使用完整版","date":"2020-04-14T07:12:51.251Z","updated":"2020-04-14T07:16:36.603Z","comments":true,"path":"2020/04/14/Docker下Gitlab安装配置使用完整版/","link":"","permalink":"http://coolwin8.github.io/2020/04/14/Docker%E4%B8%8BGitlab%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E4%BD%BF%E7%94%A8%E5%AE%8C%E6%95%B4%E7%89%88/","excerpt":"","text":"一、安装及配置1.gitlab镜像拉取12# gitlab-ce为稳定版本，后面不填写版本则默认pull最新latest版本$ docker pull gitlab/gitlab-ce 拉取镜像 2.运行gitlab镜像12345$ docker run -d -p 443:443 -p 80:80 -p 222:22 --name gitlab --restart always -v /home/gitlab/config:/etc/gitlab -v /home/gitlab/logs:/var/log/gitlab -v /home/gitlab/data:/var/opt/gitlab gitlab/gitlab-ce# -d：后台运行# -p：将容器内部端口向外映射# --name：命名容器名称# -v：将容器内数据文件夹或者日志、配置等文件夹挂载到宿主机指定目录 运行成功后出现一串字符串 运行成功 3.配置按上面的方式，gitlab容器运行没问题，但在gitlab上创建项目的时候，生成项目的URL访问地址是按容器的hostname来生成的，也就是容器的id。作为gitlab服务器，我们需要一个固定的URL访问地址，于是需要配置gitlab.rb（宿主机路径：/home/gitlab/config/gitlab.rb）。 12# gitlab.rb文件内容默认全是注释$ vim /home/gitlab/config/gitlab.rb 1234567# 配置http协议所使用的访问地址,不加端口号默认为80external_url 'http://192.168.199.231'# 配置ssh协议所使用的访问地址和端口gitlab_rails['gitlab_ssh_host'] = '192.168.199.231'gitlab_rails['gitlab_shell_ssh_port'] = 222 # 此端口是run时22端口映射的222端口:wq #保存配置文件并退出 修改gitlab.rb文件 12# 重启gitlab容器$ docker restart gitlab 此时项目的仓库地址就变了。如果ssh端口地址不是默认的22，就会加上ssh:// 协议头打开浏览器输入ip地址(因为我的gitlab端口为80，所以浏览器url不用输入端口号，如果端口号不是80，则打开为：ip:端口号) 4.创建一个项目第一次进入要输入新的root用户密码，设置好之后确定就行 gitlab页面 下面我们就可以新建一个项目了，点击Create a project Create a project 创建完成后： 创建完成！ 二、用户使用1.下载git.exe双击git.exe安装git（一直点下一步，直到完成）点击电脑桌面空白地方右键看到如下两行即安装成功 image.png 2.登录gitlab网页 url：http://192.168.1.111填写账号密码登录 登录页面 3.设置ssh1.打开本地git bash,使用如下命令生成ssh公钥和私钥对 1$ ssh-keygen -t rsa -C 'xxx@xxx.com' 然后一路回车(-C 参数是你的邮箱地址) 生成密匙 2.然后输入命令： 12# ~表示用户目录，比如我的windows就是C:\\Users\\Administrator，并复制其中的内容$ cat ~/.ssh/id_rsa.pub 3.打开gitlab,找到Profile Settings–&gt;SSH Keys—&gt;Add SSH Key,并把上一步中复制的内容粘贴到Key所对应的文本框 添加公匙到gitlab 4.从gitlab克隆代码1.回到gitlab页面点击projects-&gt;your projects 2.选择一个需要克隆的项目，进入 我的项目页面 3.点击按钮复制地址 4.新建一个文件夹，我在这里在我的电脑D盘下新建project文件夹 5.进入projects文件夹右键选择-&gt;Git Bash Here 点击Git Bash Here 6.设置用户名和邮箱 12$ git config --global user.name \"你的名字\"$ git config --global user.email \"你的邮箱\" 7.克隆项目 1$ git clone 项目地址 8.查看projects文件夹，项目已经克隆下来了 5.提交代码到gitlab1.基于以上步骤，在克隆的项目文件夹下新增一个测试文件 新增txt文件 2.查看同步状态在项目文件夹下右键点击-&gt;Git Bash Here 输入 1$ git status 状态可以看到红色部分有需要提交的文件 3.提交代码输入 1$ git add 测试提交的文件.txt (“git add“后加“.”则添加全部文件，也可以加”*.txt”表示添加全部需要提交的txt文件 ) add需要提交的文件 然后输入以下命令提交并添加提交信息 1$ git commit -m \"message\" commit 最后输出以下命令提交到gitlab 1$ git push origin master push 提交完成啦再回到gitlab上看该项目就可以看到多了一个txt测试文件","categories":[{"name":"配置管理","slug":"配置管理","permalink":"http://coolwin8.github.io/categories/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://coolwin8.github.io/tags/gitlab/"},{"name":"docker","slug":"docker","permalink":"http://coolwin8.github.io/tags/docker/"},{"name":"DevOps","slug":"DevOps","permalink":"http://coolwin8.github.io/tags/DevOps/"}]},{"title":"maven连接nexus私服配置文件详解","slug":"maven连接nexus私服配置文件详解","date":"2020-04-13T12:39:53.000Z","updated":"2020-04-13T04:46:22.321Z","comments":true,"path":"2020/04/13/maven连接nexus私服配置文件详解/","link":"","permalink":"http://coolwin8.github.io/2020/04/13/maven%E8%BF%9E%E6%8E%A5nexus%E7%A7%81%E6%9C%8D%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"settings.xml有什么用？ 如果在Eclipse中使用过Maven插件，想必会有这个经验：配置settings.xml文件的路径。 settings.xml文件是干什么的，为什么要配置它呢？从settings.xml的文件名就可以看出，它是用来设置maven参数的配置文件。并且，settings.xml是maven的全局配置文件。而pom.xml文件是所在项目的局部配置。Settings.xml中包含类似本地仓储位置、修改远程仓储服务器、认证信息等配置。 settings.xml文件位置 settings.xml文件一般存在于两个位置：全局配置: ${M2_HOME}/conf/settings.xml用户配置: {user.home} 和和所有其他系统属性只能在3.0+版本上使用。请注意windows和Linux使用变量的区别。 配置优先级 需要注意的是：局部配置优先于全局配置。配置优先级从高到低：pom.xml&gt; user settings &gt; global settings如果这些文件同时存在，在应用配置时，会合并它们的内容，如果有重复的配置，优先级高的配置会覆盖优先级低的。 maven怎么从远程仓库下载jar包 setting中配置： &lt;!-- 我们使用maven下载需要的jar包，但是很多的时候由于中央仓库没有,所以此处可以在maven的设置中心添加多个下载仓库，当中央仓库没有的话，继续到下一个仓库去下载。这样丰富了中央仓库的下载地址。 --&gt; &lt;mirror&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;nexus maven&lt;/name&gt; &lt;url&gt;http://localhost:8081/repository/maven-public/&lt;/url&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;repo2&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://repo2.maven.org/maven2/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;Nexus配置项目使用nexus私服的jar包，在项目的pom.xml文件中指定私服仓库 12345678910111213&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;&#x2F;id&gt; &lt;name&gt;nexus&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;192.168.1.103:8081&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;snapshots&gt; &lt;&#x2F;repository&gt; &lt;&#x2F;repositories&gt; 项目使用nexus私服的插件，在项目的pom.xml文件中指定插件仓库 12345678910111213&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;&#x2F;id&gt; &lt;name&gt;nexus&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;192.168.1.103:8081&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;snapshots&gt; &lt;&#x2F;pluginRepository&gt; &lt;&#x2F;pluginRepositories&gt; 如果想本机所有的maven项目都使用私服的组件，可以在maven的设置文件settings.xml中添加属性，并激活 12345678910111213141516171819202122232425262728&lt;profile&gt; &lt;id&gt;Nexus&lt;&#x2F;id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;&#x2F;id&gt; &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;maven-public&#x2F;&lt;&#x2F;url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;&#x2F;enabled&gt;&lt;&#x2F;releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;&#x2F;enabled&gt;&lt;&#x2F;snapshots&gt; &lt;&#x2F;repository&gt; &lt;&#x2F;repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;&#x2F;id&gt; &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;maven-public&#x2F;&lt;&#x2F;url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;&#x2F;enabled&gt; &lt;&#x2F;snapshots&gt; &lt;&#x2F;pluginRepository&gt; &lt;&#x2F;pluginRepositories&gt; &lt;&#x2F;profile&gt; &lt;&#x2F;profiles&gt; &lt;!-- 激活 --&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;Nexus&lt;&#x2F;activeProfile&gt; &lt;&#x2F;activeProfiles&gt; 如何将自己的项目发布到nexus私服 我们知道用mvn install命令可以将项目装载的本地的仓库，但是项目发布到私服，maven项目就要使用命令：mvn clean deploy；要想发布项目到nexus里，必须通过标签来进行配置。在之前的文章中有介绍nexus的工厂类别，其中提到两个：hosted里的Releases、Snapshots. 当我们发布项目到nexus里时，如果项目版本是x.x.x-Releases，则会发布到Releases工厂中；而项目版本是x.x.x-SNAPSHOTS则发布到Snapshots工厂中。需要在pom文件中配置一下代码； 123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;&#x2F;id&gt; &lt;name&gt;Nexus Release Repository&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;maven-releases&#x2F;&lt;&#x2F;url&gt; &lt;&#x2F;repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;&#x2F;id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;localhost:8081&#x2F;repository&#x2F;maven-snapshots&#x2F;&#x2F;&lt;&#x2F;url&gt; &lt;&#x2F;snapshotRepository&gt; &lt;&#x2F;distributionManagement&gt; 注意还需要配置mvn发布的权限，否则会报401错误，在settings.xml中配置权限，其中id要与pom文件中的id一致 1234567891011&lt;!--授权信息 --&gt; &lt;server&gt; &lt;id&gt;nexus-releases&lt;&#x2F;id&gt; &lt;username&gt;admin&lt;&#x2F;username&gt; &lt;password&gt;admin123&lt;&#x2F;password&gt; &lt;&#x2F;server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;&#x2F;id&gt; &lt;username&gt;admin&lt;&#x2F;username&gt; &lt;password&gt;admin123&lt;&#x2F;password&gt; &lt;&#x2F;server&gt; 这里面的username和password对应的是nexus私服中具有发布权限的用户名和密码","categories":[{"name":"java maven","slug":"java-maven","permalink":"http://coolwin8.github.io/categories/java-maven/"}],"tags":[{"name":"配置管理","slug":"配置管理","permalink":"http://coolwin8.github.io/tags/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"},{"name":"maven","slug":"maven","permalink":"http://coolwin8.github.io/tags/maven/"},{"name":"nexus","slug":"nexus","permalink":"http://coolwin8.github.io/tags/nexus/"}]},{"title":"机器学习如何选择特征","slug":"机器学习如何选择特征","date":"2020-04-11T06:11:56.583Z","updated":"2020-04-11T06:23:54.817Z","comments":true,"path":"2020/04/11/机器学习如何选择特征/","link":"","permalink":"http://coolwin8.github.io/2020/04/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E7%89%B9%E5%BE%81/","excerpt":"","text":"看到一篇好文章分享出来，看别人是如何选特征的，作者是Edwin Jarvis 作者：Edwin Jarvis 特征选择(排序)对于数据科学家、机器学习从业者来说非常重要。好的特征选择能够提升模型的性能，更能帮助我们理解数据的特点、底层结构，这对进一步改善模型、算法都有着重要作用。 特征选择主要有两个功能： 减少特征数量、降维，使模型泛化能力更强，减少过拟合 增强对特征和特征值之间的理解 拿到数据集，一个特征选择方法，往往很难同时完成这两个目的。通常情况下，我们经常不管三七二十一，选择一种自己最熟悉或者最方便的特征选择方法（往往目的是降维，而忽略了对特征和数据理解的目的）。 在许多机器学习相关的书里，很难找到关于特征选择的内容，因为特征选择要解决的问题往往被视为机器学习的一种副作用，一般不会单独拿出来讨论。 本文将结合Scikit-learn提供的例子介绍几种常用的特征选择方法，它们各自的优缺点和问题。 1 去掉取值变化小的特征 Removing features with low variance这应该是最简单的特征选择方法了：假设某特征的特征值只有0和1，并且在所有输入样本中，95%的实例的该特征取值都是1，那就可以认为这个特征作用不大。如果100%都是1，那这个特征就没意义了。当特征值都是离散型变量的时候这种方法才能用，如果是连续型变量，就需要将连续变量离散化之后才能用，而且实际当中，一般不太会有95%以上都取某个值的特征存在，所以这种方法虽然简单但是不太好用。可以把它作为特征选择的预处理，先去掉那些取值变化小的特征，然后再从接下来提到的的特征选择方法中选择合适的进行进一步的特征选择。 2 单变量特征选择 Univariate feature selection单变量特征选择能够对每一个特征进行测试，衡量该特征和响应变量之间的关系，根据得分扔掉不好的特征。对于回归和分类问题可以采用卡方检验等方式对特征进行测试。 这种方法比较简单，易于运行，易于理解，通常对于理解数据有较好的效果（但对特征优化、提高泛化能力来说不一定有效）；这种方法有许多改进的版本、变种。 2.1 Pearson相关系数 Pearson Correlation皮尔森相关系数是一种最简单的，能帮助理解特征和响应变量之间关系的方法，该方法衡量的是变量之间的==线性\b相关性==，结果的取值区间为[-1，1]，-1表示完全的负相关(这个变量下降，那个就会上升)，+1表示完全的正相关，0表示没有线性相关。 Pearson Correlation速度快、易于计算，经常在拿到数据(经过清洗和特征提取之后的)之后第一时间就执行。Scipy的pearsonr方法能够同时计算相关系数和p-value， 12345678import numpy as npfrom scipy.stats import pearsonrnp.random.seed(0)size &#x3D; 300x &#x3D; np.random.normal(0, 1, size)print &quot;Lower noise&quot;, pearsonr(x, x + np.random.normal(0, 1, size))print &quot;Higher noise&quot;, pearsonr(x, x + np.random.normal(0, 10, size)) Lower noise (0.71824836862138386, 7.3240173129992273e-49)Higher noise (0.057964292079338148, 0.31700993885324746) 这个例子中，我们比较了变量在加入噪音之前和之后的差异。当噪音比较小的时候，相关性很强，p-value很低。 Scikit-learn提供的f_regrssion方法能够批量计算特征的p-value，非常方便，参考sklearn的pipeline Pearson相关系数的一个明显缺陷是，作为特征排序机制，他只对线性关系敏感。如果关系是非线性的，即便两个变量具有一一对应的关系，Pearson相关性也可能会接近0。 12x &#x3D; np.random.uniform(-1, 1, 100000)print pearsonr(x, x**2)[0] -0.00230804707612 更多类似的例子参考sample plots。另外，如果仅仅根据相关系数这个值来判断的话，有时候会具有很强的误导性，如Anscombe’s quartet，最好把数据可视化出来，以免得出错误的结论。 2.2 互信息和最大信息系数 Mutual information and maximal information coefficient (MIC)以上就是经典的互信息公式了。想把互信息直接用于特征选择其实不是太方便：1、它不属于度量方式，也没有办法归一化，在不同数据及上的结果无法做比较；2、对于连续变量的计算不是很方便（X和Y都是集合，x，y都是离散的取值），通常变量需要先离散化，而互信息的结果对离散化的方式很敏感。 最大信息系数克服了这两个问题。它首先寻找一种最优的离散化方式，然后把互信息取值转换成一种度量方式，取值区间在[0，1]。minepy提供了MIC功能。 反过头来看y=x^2这个例子，MIC算出来的互信息值为1(最大的取值)。 123456from minepy import MINEm &#x3D; MINE()x &#x3D; np.random.uniform(-1, 1, 10000)m.compute_score(x, x**2)print m.mic() 1.0 MIC的统计能力遭到了一些质疑，当零假设不成立时，MIC的统计就会受到影响。在有的数据集上不存在这个问题，但有的数据集上就存在这个问题。 2.3 距离相关系数 (Distance correlation)距离相关系数是为了克服Pearson相关系数的弱点而生的。在x和x^2这个例子中，即便Pearson相关系数是0，我们也不能断定这两个变量是独立的（有可能是非线性相关）；但如果距离相关系数是0，那么我们就可以说这两个变量是独立的。 R的energy包里提供了距离相关系数的实现，另外这是Python gist的实现。 1234#R-code&gt; x &#x3D; runif (1000, -1, 1)&gt; dcor(x, x**2)[1] 0.4943864 尽管有MIC和距离相关系数在了，但当变量之间的关系接近线性相关的时候，Pearson相关系数仍然是不可替代的。第一、Pearson相关系数计算速度快，这在处理大规模数据的时候很重要。第二、Pearson相关系数的取值区间是[-1，1]，而MIC和距离相关系数都是[0，1]。这个特点使得Pearson相关系数能够表征更丰富的关系，符号表示关系的正负，绝对值能够表示强度。当然，Pearson相关性有效的前提是两个变量的变化关系是单调的。 2.4 基于学习模型的特征排序 (Model based ranking)这种方法的思路是直接使用你要用的机器学习算法，针对每个单独的特征和响应变量建立预测模型。其实Pearson相关系数等价于线性回归里的标准化回归系数。假如某个特征和响应变量之间的关系是非线性的，可以用基于树的方法（决策树、随机森林）、或者扩展的线性模型等。基于树的方法比较易于使用，因为他们对非线性关系的建模比较好，并且不需要太多的调试。但要注意过拟合问题，因此树的深度最好不要太大，再就是运用交叉验证。 在波士顿房价数据集上使用sklearn的随机森林回归给出一个单变量选择的例子： 1234567891011121314151617from sklearn.cross_validation import cross_val_score, ShuffleSplitfrom sklearn.datasets import load_bostonfrom sklearn.ensemble import RandomForestRegressor#Load boston housing dataset as an exampleboston &#x3D; load_boston()X &#x3D; boston[&quot;data&quot;]Y &#x3D; boston[&quot;target&quot;]names &#x3D; boston[&quot;feature_names&quot;]rf &#x3D; RandomForestRegressor(n_estimators&#x3D;20, max_depth&#x3D;4)scores &#x3D; []for i in range(X.shape[1]): score &#x3D; cross_val_score(rf, X[:, i:i+1], Y, scoring&#x3D;&quot;r2&quot;, cv&#x3D;ShuffleSplit(len(X), 3, .3)) scores.append((round(np.mean(score), 3), names[i]))print sorted(scores, reverse&#x3D;True) [(0.636, ‘LSTAT’), (0.59, ‘RM’), (0.472, ‘NOX’), (0.369, ‘INDUS’), (0.311, ‘PTRATIO’), (0.24, ‘TAX’), (0.24, ‘CRIM’), (0.185, ‘RAD’), (0.16, ‘ZN’), (0.087, ‘B’), (0.062, ‘DIS’), (0.036, ‘CHAS’), (0.027, ‘AGE’)] 3 线性模型和正则化单变量特征选择方法独立的衡量每个特征与响应变量之间的关系，另一种主流的特征选择方法是基于机器学习模型的方法。有些机器学习方法本身就具有对特征进行打分的机制，或者很容易将其运用到特征选择任务中，例如回归模型，SVM，决策树，随机森林等等。说句题外话，这种方法好像在一些地方叫做wrapper类型，大概意思是说，特征排序模型和机器学习模型是耦盒在一起的，对应的非wrapper类型的特征选择方法叫做filter类型。 下面将介绍如何用回归模型的系数来选择特征。越是重要的特征在模型中对应的系数就会越大，而跟输出变量越是无关的特征对应的系数就会越接近于0。在噪音不多的数据上，或者是数据量远远大于特征数的数据上，如果特征之间相对来说是比较独立的，那么即便是运用最简单的线性回归模型也一样能取得非常好的效果。 123456789101112131415161718192021222324from sklearn.linear_model import LinearRegressionimport numpy as npnp.random.seed(0)size &#x3D; 5000#A dataset with 3 featuresX &#x3D; np.random.normal(0, 1, (size, 3))#Y &#x3D; X0 + 2*X1 + noiseY &#x3D; X[:,0] + 2*X[:,1] + np.random.normal(0, 2, size)lr &#x3D; LinearRegression()lr.fit(X, Y)#A helper method for pretty-printing linear modelsdef pretty_print_linear(coefs, names &#x3D; None, sort &#x3D; False): if names &#x3D;&#x3D; None: names &#x3D; [&quot;X%s&quot; % x for x in range(len(coefs))] lst &#x3D; zip(coefs, names) if sort: lst &#x3D; sorted(lst, key &#x3D; lambda x:-np.abs(x[0])) return &quot; + &quot;.join(&quot;%s * %s&quot; % (round(coef, 3), name) for coef, name in lst)print &quot;Linear model:&quot;, pretty_print_linear(lr.coef_) Linear model: 0.984 * X0 + 1.995 * X1 + -0.041 * X2 在这个例子当中，尽管数据中存在一些噪音，但这种特征选择模型仍然能够很好的体现出数据的底层结构。当然这也是因为例子中的这个问题非常适合用线性模型来解：特征和响应变量之间全都是线性关系，并且特征之间均是独立的。 在很多实际的数据当中，往往存在多个互相关联的特征，这时候模型就会变得不稳定，数据中细微的变化就可能导致模型的巨大变化（模型的变化本质上是系数，或者叫参数，可以理解成W），这会让模型的预测变得困难，这种现象也称为多重共线性。例如，假设我们有个数据集，它的真实模型应该是Y=X1+X2，当我们观察的时候，发现Y’=X1+X2+e，e是噪音。如果X1和X2之间存在线性关系，例如X1约等于X2，这个时候由于噪音e的存在，我们学到的模型可能就不是Y=X1+X2了，有可能是Y=2X1，或者Y=-X1+3X2。 下边这个例子当中，在同一个数据上加入了一些噪音，用随机森林算法进行特征选择。 12345678910111213141516from sklearn.linear_model import LinearRegressionsize &#x3D; 100np.random.seed(seed&#x3D;5)X_seed &#x3D; np.random.normal(0, 1, size)X1 &#x3D; X_seed + np.random.normal(0, .1, size)X2 &#x3D; X_seed + np.random.normal(0, .1, size)X3 &#x3D; X_seed + np.random.normal(0, .1, size)Y &#x3D; X1 + X2 + X3 + np.random.normal(0,1, size)X &#x3D; np.array([X1, X2, X3]).Tlr &#x3D; LinearRegression()lr.fit(X,Y)print &quot;Linear model:&quot;, pretty_print_linear(lr.coef_) Linear model: -1.291 * X0 + 1.591 * X1 + 2.747 * X2 系数之和接近3，基本上和上上个例子的结果一致，应该说学到的模型对于预测来说还是不错的。但是，如果从系数的字面意思上去解释特征的重要性的话，X3对于输出变量来说具有很强的正面影响，而X1具有负面影响，而实际上所有特征与输出变量之间的影响是均等的。 同样的方法和套路可以用到类似的线性模型上，比如逻辑回归。 3.1 正则化模型正则化就是把额外的约束或者惩罚项加到已有模型（损失函数）上，以防止过拟合并提高泛化能力。损失函数由原来的E(X,Y)变为E(X,Y)+alpha||w||，w是模型系数组成的向量（有些地方也叫参数parameter，coefficients），||·||一般是L1或者L2范数，alpha是一个可调的参数，控制着正则化的强度。当用在线性模型上时，L1正则化和L2正则化也称为Lasso和Ridge。 3.2 L1正则化/LassoL1正则化将系数w的l1范数作为惩罚项加到损失函数上，由于正则项非零，这就迫使那些弱的特征所对应的系数变成0。因此L1正则化往往会使学到的模型很稀疏（系数w经常为0），这个特性使得L1正则化成为一种很好的特征选择方法。 Scikit-learn为线性回归提供了Lasso，为分类提供了L1逻辑回归。 下面的例子在波士顿房价数据上运行了Lasso，其中参数alpha是通过grid search进行优化的。 1234567891011121314from sklearn.linear_model import Lassofrom sklearn.preprocessing import StandardScalerfrom sklearn.datasets import load_bostonboston &#x3D; load_boston()scaler &#x3D; StandardScaler()X &#x3D; scaler.fit_transform(boston[&quot;data&quot;])Y &#x3D; boston[&quot;target&quot;]names &#x3D; boston[&quot;feature_names&quot;]lasso &#x3D; Lasso(alpha&#x3D;.3)lasso.fit(X, Y)print &quot;Lasso model: &quot;, pretty_print_linear(lasso.coef_, names, sort &#x3D; True) Lasso model: -3.707 * LSTAT + 2.992 * RM + -1.757 * PTRATIO + -1.081 * DIS + -0.7 * NOX + 0.631 * B + 0.54 * CHAS + -0.236 * CRIM + 0.081 * ZN + -0.0 * INDUS + -0.0 * AGE + 0.0 * RAD + -0.0 * TAX 可以看到，很多特征的系数都是0。如果继续增加alpha的值，得到的模型就会越来越稀疏，即越来越多的特征系数会变成0。 然而，L1正则化像非正则化线性模型一样也是不稳定的，如果特征集合中具有相关联的特征，当数据发生细微变化时也有可能导致很大的模型差异。 3.3 L2正则化/Ridge regressionL2正则化将系数向量的L2范数添加到了损失函数中。由于L2惩罚项中系数是二次方的，这使得L2和L1有着诸多差异，最明显的一点就是，L2正则化会让系数的取值变得平均。对于关联特征，这意味着他们能够获得更相近的对应系数。还是以Y=X1+X2为例，假设X1和X2具有很强的关联，如果用L1正则化，不论学到的模型是Y=X1+X2还是Y=2X1，惩罚都是一样的，都是2alpha。但是对于L2来说，第一个模型的惩罚项是2alpha，但第二个模型的是4*alpha。可以看出，系数之和为常数时，各系数相等时惩罚是最小的，所以才有了L2会让各个系数趋于相同的特点。 可以看出，L2正则化对于特征选择来说一种稳定的模型，不像L1正则化那样，系数会因为细微的数据变化而波动。所以L2正则化和L1正则化提供的价值是不同的，L2正则化对于特征理解来说更加有用：表示能力强的特征对应的系数是非零。 回过头来看看3个互相关联的特征的例子，分别以10个不同的种子随机初始化运行10次，来观察L1和L2正则化的稳定性。 123456789101112131415161718192021222324from sklearn.linear_model import Ridgefrom sklearn.metrics import r2_scoresize &#x3D; 100#We run the method 10 times with different random seedsfor i in range(10): print &quot;Random seed %s&quot; % i np.random.seed(seed&#x3D;i) X_seed &#x3D; np.random.normal(0, 1, size) X1 &#x3D; X_seed + np.random.normal(0, .1, size) X2 &#x3D; X_seed + np.random.normal(0, .1, size) X3 &#x3D; X_seed + np.random.normal(0, .1, size) Y &#x3D; X1 + X2 + X3 + np.random.normal(0, 1, size) X &#x3D; np.array([X1, X2, X3]).T lr &#x3D; LinearRegression() lr.fit(X,Y) print &quot;Linear model:&quot;, pretty_print_linear(lr.coef_) ridge &#x3D; Ridge(alpha&#x3D;10) ridge.fit(X,Y) print &quot;Ridge model:&quot;, pretty_print_linear(ridge.coef_) print Random seed 0 Linear model: 0.728 * X0 + 2.309 * X1 + -0.082 * X2 Ridge model: 0.938 * X0 + 1.059 * X1 + 0.877 * X2 Random seed 1 Linear model: 1.152 * X0 + 2.366 * X1 + -0.599 * X2 Ridge model: 0.984 * X0 + 1.068 * X1 + 0.759 * X2 Random seed 2 Linear model: 0.697 * X0 + 0.322 * X1 + 2.086 * X2 Ridge model: 0.972 * X0 + 0.943 * X1 + 1.085 * X2 Random seed 3 Linear model: 0.287 * X0 + 1.254 * X1 + 1.491 * X2 Ridge model: 0.919 * X0 + 1.005 * X1 + 1.033 * X2 Random seed 4 Linear model: 0.187 * X0 + 0.772 * X1 + 2.189 * X2 Ridge model: 0.964 * X0 + 0.982 * X1 + 1.098 * X2 Random seed 5 Linear model: -1.291 * X0 + 1.591 * X1 + 2.747 * X2 Ridge model: 0.758 * X0 + 1.011 * X1 + 1.139 * X2 Random seed 6 Linear model: 1.199 * X0 + -0.031 * X1 + 1.915 * X2 Ridge model: 1.016 * X0 + 0.89 * X1 + 1.091 * X2 Random seed 7 Linear model: 1.474 * X0 + 1.762 * X1 + -0.151 * X2 Ridge model: 1.018 * X0 + 1.039 * X1 + 0.901 * X2 Random seed 8 Linear model: 0.084 * X0 + 1.88 * X1 + 1.107 * X2 Ridge model: 0.907 * X0 + 1.071 * X1 + 1.008 * X2 Random seed 9 Linear model: 0.714 * X0 + 0.776 * X1 + 1.364 * X2 Ridge model: 0.896 * X0 + 0.903 * X1 + 0.98 * X2 可以看出，不同的数据上线性回归得到的模型（系数）相差甚远，但对于L2正则化模型来说，结果中的系数非常的稳定，差别较小，都比较接近于1，能够反映出数据的内在结构。 4 随机森林随机森林具有准确率高、鲁棒性好、易于使用等优点，这使得它成为了目前最流行的机器学习算法之一。随机森林提供了两种特征选择的方法：mean decrease impurity和mean decrease accuracy。 4.1 平均不纯度减少 mean decrease impurity随机森林由多个决策树构成。决策树中的每一个节点都是关于某个特征的条件，为的是将数据集按照不同的响应变量一分为二。利用不纯度可以确定节点（最优条件），对于分类问题，通常采用基尼不纯度或者信息增益，对于回归问题，通常采用的是方差或者最小二乘拟合。当训练决策树的时候，可以计算出每个特征减少了多少树的不纯度。对于一个决策树森林来说，可以算出每个特征平均减少了多少不纯度，并把它平均减少的不纯度作为特征选择的值。 下边的例子是sklearn中基于随机森林的特征重要度度量方法： 1234567891011121314from sklearn.datasets import load_bostonfrom sklearn.ensemble import RandomForestRegressorimport numpy as np#Load boston housing dataset as an exampleboston &#x3D; load_boston()X &#x3D; boston[&quot;data&quot;]Y &#x3D; boston[&quot;target&quot;]names &#x3D; boston[&quot;feature_names&quot;]rf &#x3D; RandomForestRegressor()rf.fit(X, Y)print &quot;Features sorted by their score:&quot;print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), reverse&#x3D;True) Features sorted by their score: [(0.5298, ‘LSTAT’), (0.4116, ‘RM’), (0.0252, ‘DIS’), (0.0172, ‘CRIM’), (0.0065, ‘NOX’), (0.0035, ‘PTRATIO’), (0.0021, ‘TAX’), (0.0017, ‘AGE’), (0.0012, ‘B’), (0.0008, ‘INDUS’), (0.0004, ‘RAD’), (0.0001, ‘CHAS’), (0.0, ‘ZN’)] 这里特征得分实际上采用的是Gini Importance。使用基于不纯度的方法的时候，要记住：1、这种方法存在偏向，对具有更多类别的变量会更有利；2、对于存在关联的多个特征，其中任意一个都可以作为指示器（优秀的特征），并且一旦某个特征被选择之后，其他特征的重要度就会急剧下降，因为不纯度已经被选中的那个特征降下来了，其他的特征就很难再降低那么多不纯度了，这样一来，只有先被选中的那个特征重要度很高，其他的关联特征重要度往往较低。在理解数据时，这就会造成误解，导致错误的认为先被选中的特征是很重要的，而其余的特征是不重要的，但实际上这些特征对响应变量的作用确实非常接近的（这跟Lasso是很像的）。 特征随机选择方法稍微缓解了这个问题，但总的来说并没有完全解决。下面的例子中，X0、X1、X2是三个互相关联的变量，在没有噪音的情况下，输出变量是三者之和。 12345678910111213size &#x3D; 10000np.random.seed(seed&#x3D;10)X_seed &#x3D; np.random.normal(0, 1, size)X0 &#x3D; X_seed + np.random.normal(0, .1, size)X1 &#x3D; X_seed + np.random.normal(0, .1, size)X2 &#x3D; X_seed + np.random.normal(0, .1, size)X &#x3D; np.array([X0, X1, X2]).TY &#x3D; X0 + X1 + X2rf &#x3D; RandomForestRegressor(n_estimators&#x3D;20, max_features&#x3D;2)rf.fit(X, Y);print &quot;Scores for X0, X1, X2:&quot;, map(lambda x:round (x,3), rf.feature_importances_) Scores for X0, X1, X2: [0.278, 0.66, 0.062] 当计算特征重要性时，可以看到X1的重要度比X2的重要度要高出10倍，但实际上他们真正的重要度是一样的。尽管数据量已经很大且没有噪音，且用了20棵树来做随机选择，但这个问题还是会存在。 需要注意的一点是，关联特征的打分存在不稳定的现象，这不仅仅是随机森林特有的，大多数基于模型的特征选择方法都存在这个问题。 4.2 平均精确率减少 Mean decrease accuracy另一种常用的特征选择方法就是直接度量每个特征对模型精确率的影响。主要思路是打乱每个特征的特征值顺序，并且度量顺序变动对模型的精确率的影响。很明显，对于不重要的变量来说，打乱顺序对模型的精确率影响不会太大，但是对于重要的变量来说，打乱顺序就会降低模型的精确率。 这个方法sklearn中没有直接提供，但是很容易实现，下面继续在波士顿房价数据集上进行实现。 123456789101112131415161718192021222324from sklearn.cross_validation import ShuffleSplitfrom sklearn.metrics import r2_scorefrom collections import defaultdictX &#x3D; boston[&quot;data&quot;]Y &#x3D; boston[&quot;target&quot;]rf &#x3D; RandomForestRegressor()scores &#x3D; defaultdict(list)#crossvalidate the scores on a number of different random splits of the datafor train_idx, test_idx in ShuffleSplit(len(X), 100, .3): X_train, X_test &#x3D; X[train_idx], X[test_idx] Y_train, Y_test &#x3D; Y[train_idx], Y[test_idx] r &#x3D; rf.fit(X_train, Y_train) acc &#x3D; r2_score(Y_test, rf.predict(X_test)) for i in range(X.shape[1]): X_t &#x3D; X_test.copy() np.random.shuffle(X_t[:, i]) shuff_acc &#x3D; r2_score(Y_test, rf.predict(X_t)) scores[names[i]].append((acc-shuff_acc)&#x2F;acc)print &quot;Features sorted by their score:&quot;print sorted([(round(np.mean(score), 4), feat) for feat, score in scores.items()], reverse&#x3D;True) Features sorted by their score: [(0.7276, ‘LSTAT’), (0.5675, ‘RM’), (0.0867, ‘DIS’), (0.0407, ‘NOX’), (0.0351, ‘CRIM’), (0.0233, ‘PTRATIO’), (0.0168, ‘TAX’), (0.0122, ‘AGE’), (0.005, ‘B’), (0.0048, ‘INDUS’), (0.0043, ‘RAD’), (0.0004, ‘ZN’), (0.0001, ‘CHAS’)] 在这个例子当中，LSTAT和RM这两个特征对模型的性能有着很大的影响，打乱这两个特征的特征值使得模型的性能下降了73%和57%。注意，尽管这些我们是在所有特征上进行了训练得到了模型，然后才得到了每个特征的重要性测试，这并不意味着我们扔掉某个或者某些重要特征后模型的性能就一定会下降很多，因为即便某个特征删掉之后，其关联特征一样可以发挥作用，让模型性能基本上不变。 5 两种顶层特征选择算法之所以叫做顶层，是因为他们都是建立在基于模型的特征选择方法基础之上的，例如回归和SVM，在不同的子集上建立模型，然后汇总最终确定特征得分。 5.1 稳定性选择 Stability selection稳定性选择是一种基于二次抽样和选择算法相结合较新的方法，选择算法可以是回归、SVM或其他类似的方法。它的主要思想是在不同的数据子集和特征子集上运行特征选择算法，不断的重复，最终汇总特征选择结果，比如可以统计某个特征被认为是重要特征的频率（被选为重要特征的次数除以它所在的子集被测试的次数）。理想情况下，重要特征的得分会接近100%。稍微弱一点的特征得分会是非0的数，而最无用的特征得分将会接近于0。 sklearn在随机lasso和随机逻辑回归中有对稳定性选择的实现。 12345678910111213141516from sklearn.linear_model import RandomizedLassofrom sklearn.datasets import load_bostonboston &#x3D; load_boston()#using the Boston housing data. #Data gets scaled automatically by sklearn&#39;s implementationX &#x3D; boston[&quot;data&quot;]Y &#x3D; boston[&quot;target&quot;]names &#x3D; boston[&quot;feature_names&quot;]rlasso &#x3D; RandomizedLasso(alpha&#x3D;0.025)rlasso.fit(X, Y)print &quot;Features sorted by their score:&quot;print sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), names), reverse&#x3D;True) Features sorted by their score: [(1.0, ‘RM’), (1.0, ‘PTRATIO’), (1.0, ‘LSTAT’), (0.62, ‘CHAS’), (0.595, ‘B’), (0.39, ‘TAX’), (0.385, ‘CRIM’), (0.25, ‘DIS’), (0.22, ‘NOX’), (0.125, ‘INDUS’), (0.045, ‘ZN’), (0.02, ‘RAD’), (0.015, ‘AGE’)] 在上边这个例子当中，最高的3个特征得分是1.0，这表示他们总会被选作有用的特征（当然，得分会收到正则化参数alpha的影响，但是sklearn的随机lasso能够自动选择最优的alpha）。接下来的几个特征得分就开始下降，但是下降的不是特别急剧，这跟纯lasso的方法和随机森林的结果不一样。能够看出稳定性选择对于克服过拟合和对数据理解来说都是有帮助的：总的来说，好的特征不会因为有相似的特征、关联特征而得分为0，这跟Lasso是不同的。对于特征选择任务，在许多数据集和环境下，稳定性选择往往是性能最好的方法之一。 5.2 递归特征消除 Recursive feature elimination (RFE)递归特征消除的主要思想是反复的构建模型（如SVM或者回归模型）然后选出最好的（或者最差的）的特征（可以根据系数来选），把选出来的特征放到一遍，然后在剩余的特征上重复这个过程，直到所有特征都遍历了。这个过程中特征被消除的次序就是特征的排序。因此，这是一种寻找最优特征子集的贪心算法。 RFE的稳定性很大程度上取决于在迭代的时候底层用哪种模型。例如，假如RFE采用的普通的回归，没有经过正则化的回归是不稳定的，那么RFE就是不稳定的；假如采用的是Ridge，而用Ridge正则化的回归是稳定的，那么RFE就是稳定的。 Sklearn提供了RFE包，可以用于特征消除，还提供了RFECV，可以通过交叉验证来对的特征进行排序。 12345678910111213141516from sklearn.feature_selection import RFEfrom sklearn.linear_model import LinearRegressionboston &#x3D; load_boston()X &#x3D; boston[&quot;data&quot;]Y &#x3D; boston[&quot;target&quot;]names &#x3D; boston[&quot;feature_names&quot;]#use linear regression as the modellr &#x3D; LinearRegression()#rank all features, i.e continue the elimination until the last onerfe &#x3D; RFE(lr, n_features_to_select&#x3D;1)rfe.fit(X,Y)print &quot;Features sorted by their rank:&quot;print sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)) Features sorted by their rank: [(1.0, ‘NOX’), (2.0, ‘RM’), (3.0, ‘CHAS’), (4.0, ‘PTRATIO’), (5.0, ‘DIS’), (6.0, ‘LSTAT’), (7.0, ‘RAD’), (8.0, ‘CRIM’), (9.0, ‘INDUS’), (10.0, ‘ZN’), (11.0, ‘TAX’), (12.0, ‘B’), (13.0, ‘AGE’)] 6 一个完整的例子下面将本文所有提到的方法进行实验对比，数据集采用Friedman #1 回归数据（这篇论文中的数据）。数据是用这个公式产生的： X1到X5是由单变量分布生成的，e是标准正态变量N(0,1)。另外，原始的数据集中含有5个噪音变量 X5,…,X10，跟响应变量是独立的。我们增加了4个额外的变量X11,…X14，分别是X1,…,X4的关联变量，通过f(x)=x+N(0,0.01)生成，这将产生大于0.999的关联系数。这样生成的数据能够体现出不同的特征排序方法应对关联特征时的表现。 接下来将会在上述数据上运行所有的特征选择方法，并且将每种方法给出的得分进行归一化，让取值都落在0-1之间。对于RFE来说，由于它给出的是顺序而不是得分，我们将最好的5个的得分定为1，其他的特征的得分均匀的分布在0-1之间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384from sklearn.datasets import load_bostonfrom sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)from sklearn.feature_selection import RFE, f_regressionfrom sklearn.preprocessing import MinMaxScalerfrom sklearn.ensemble import RandomForestRegressorimport numpy as npfrom minepy import MINEnp.random.seed(0)size &#x3D; 750X &#x3D; np.random.uniform(0, 1, (size, 14))#&quot;Friedamn #1” regression problemY &#x3D; (10 * np.sin(np.pi*X[:,0]*X[:,1]) + 20*(X[:,2] - .5)**2 + 10*X[:,3] + 5*X[:,4] + np.random.normal(0,1))#Add 3 additional correlated variables (correlated with X1-X3)X[:,10:] &#x3D; X[:,:4] + np.random.normal(0, .025, (size,4))names &#x3D; [&quot;x%s&quot; % i for i in range(1,15)]ranks &#x3D; &#123;&#125;def rank_to_dict(ranks, names, order&#x3D;1): minmax &#x3D; MinMaxScaler() ranks &#x3D; minmax.fit_transform(order*np.array([ranks]).T).T[0] ranks &#x3D; map(lambda x: round(x, 2), ranks) return dict(zip(names, ranks ))lr &#x3D; LinearRegression(normalize&#x3D;True)lr.fit(X, Y)ranks[&quot;Linear reg&quot;] &#x3D; rank_to_dict(np.abs(lr.coef_), names)ridge &#x3D; Ridge(alpha&#x3D;7)ridge.fit(X, Y)ranks[&quot;Ridge&quot;] &#x3D; rank_to_dict(np.abs(ridge.coef_), names)lasso &#x3D; Lasso(alpha&#x3D;.05)lasso.fit(X, Y)ranks[&quot;Lasso&quot;] &#x3D; rank_to_dict(np.abs(lasso.coef_), names)rlasso &#x3D; RandomizedLasso(alpha&#x3D;0.04)rlasso.fit(X, Y)ranks[&quot;Stability&quot;] &#x3D; rank_to_dict(np.abs(rlasso.scores_), names)#stop the search when 5 features are left (they will get equal scores)rfe &#x3D; RFE(lr, n_features_to_select&#x3D;5)rfe.fit(X,Y)ranks[&quot;RFE&quot;] &#x3D; rank_to_dict(map(float, rfe.ranking_), names, order&#x3D;-1)rf &#x3D; RandomForestRegressor()rf.fit(X,Y)ranks[&quot;RF&quot;] &#x3D; rank_to_dict(rf.feature_importances_, names)f, pval &#x3D; f_regression(X, Y, center&#x3D;True)ranks[&quot;Corr.&quot;] &#x3D; rank_to_dict(f, names)mine &#x3D; MINE()mic_scores &#x3D; []for i in range(X.shape[1]): mine.compute_score(X[:,i], Y) m &#x3D; mine.mic() mic_scores.append(m)ranks[&quot;MIC&quot;] &#x3D; rank_to_dict(mic_scores, names)r &#x3D; &#123;&#125;for name in names: r[name] &#x3D; round(np.mean([ranks[method][name] for method in ranks.keys()]), 2)methods &#x3D; sorted(ranks.keys())ranks[&quot;Mean&quot;] &#x3D; rmethods.append(&quot;Mean&quot;)print &quot;\\t%s&quot; % &quot;\\t&quot;.join(methods)for name in names: print &quot;%s\\t%s&quot; % (name, &quot;\\t&quot;.join(map(str, [ranks[method][name] for method in methods]))) 从以上结果中可以找到一些有趣的发现： 特征之间存在线性关联关系，每个特征都是独立评价的，因此X1,…X4的得分和X11,…X14的得分非常接近，而噪音特征X5,…,X10正如预期的那样和响应变量之间几乎没有关系。由于变量X3是二次的，因此X3和响应变量之间看不出有关系（除了MIC之外，其他方法都找不到关系）。这种方法能够衡量出特征和响应变量之间的线性关系，但若想选出优质特征来提升模型的泛化能力，这种方法就不是特别给力了，因为所有的优质特征都不可避免的会被挑出来两次。 Lasso能够挑出一些优质特征，同时让其他特征的系数趋于0。当如需要减少特征数的时候它很有用，但是对于数据理解来说不是很好用。（例如在结果表中，X11,X12,X13的得分都是0，好像他们跟输出变量之间没有很强的联系，但实际上不是这样的） MIC对特征一视同仁，这一点上和关联系数有点像，另外，它能够找出X3和响应变量之间的非线性关系。 随机森林基于不纯度的排序结果非常鲜明，在得分最高的几个特征之后的特征，得分急剧的下降。从表中可以看到，得分第三的特征比第一的小4倍。而其他的特征选择算法就没有下降的这么剧烈。 Ridge将回归系数均匀的分摊到各个关联变量上，从表中可以看出，X11,…,X14和X1,…,X4的得分非常接近。 稳定性选择常常是一种既能够有助于理解数据又能够挑出优质特征的这种选择，在结果表中就能很好的看出。像Lasso一样，它能找到那些性能比较好的特征（X1，X2，X4，X5），同时，与这些特征关联度很强的变量也得到了较高的得分。 总结 对于理解数据、数据的结构、特点来说，单变量特征选择是个非常好的选择。尽管可以用它对特征进行排序来优化模型，但由于它不能发现冗余（例如假如一个特征子集，其中的特征之间具有很强的关联，那么从中选择最优的特征时就很难考虑到冗余的问题）。 正则化的线性模型对于特征理解和特征选择来说是非常强大的工具。L1正则化能够生成稀疏的模型，对于选择特征子集来说非常有用；相比起L1正则化，L2正则化的表现更加稳定，由于有用的特征往往对应系数非零，因此L2正则化对于数据的理解来说很合适。由于响应变量和特征之间往往是非线性关系，可以采用basis expansion的方式将特征转换到一个更加合适的空间当中，在此基础上再考虑运用简单的线性模型。 随机森林是一种非常流行的特征选择方法，它易于使用，一般不需要feature engineering、调参等繁琐的步骤，并且很多工具包都提供了平均不纯度下降方法。它的两个主要问题，1是重要的特征有可能得分很低（关联特征问题），2是这种方法对特征变量类别多的特征越有利（偏向问题）。尽管如此，这种方法仍然非常值得在你的应用中试一试。 特征选择在很多机器学习和数据挖掘场景中都是非常有用的。在使用的时候要弄清楚自己的目标是什么，然后找到哪种方法适用于自己的任务。当选择最优特征以提升模型性能的时候，可以采用交叉验证的方法来验证某种方法是否比其他方法要好。当用特征选择的方法来理解数据的时候要留心，特征选择模型的稳定性非常重要，稳定性差的模型很容易就会导致错误的结论。对数据进行二次采样然后在子集上运行特征选择算法能够有所帮助，如果在各个子集上的结果是一致的，那就可以说在这个数据集上得出来的结论是可信的，可以用这种特征选择模型的结果来理解数据。 Tips什么是卡方检验？用方差来衡量某个观测频率和理论频率之间差异性的方法 什么是皮尔森卡方检验？这是一种最常用的卡方检验方法，它有两个用途：1是计算某个变量对某种分布的拟合程度，2是根据两个观测变量的Contingency table来计算这两个变量是否是独立的。主要有三个步骤：第一步用方差和的方式来计算观测频率和理论频率之间卡方值；第二步算出卡方检验的自由度（行数-1乘以列数-1）；第三步比较卡方值和对应自由度的卡方分布，判断显著性。 什么是p-value？简单地说，p-value就是为了验证假设和实际之间一致性的统计学意义的值，即假设检验。有些地方叫右尾概率，根据卡方值和自由度可以算出一个固定的p-value， 什么是响应变量(response value)？简单地说，模型的输入叫做explanatroy variables，模型的输出叫做response variables，其实就是要验证该特征对结果造成了什么样的影响 什么是统计能力(statistical power)? 什么是度量(metric)? 什么是零假设(null hypothesis)?在相关性检验中，一般会取“两者之间无关联”作为零假设，而在独立性检验中，一般会取“两者之间是独立”作为零假设。与零假设相对的是备择假设（对立假设），即希望证明是正确的另一种可能。 什么是多重共线性？ 什么是grid search？","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://coolwin8.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"特征选择","slug":"特征选择","permalink":"http://coolwin8.github.io/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"},{"name":"网文精选","slug":"网文精选","permalink":"http://coolwin8.github.io/tags/%E7%BD%91%E6%96%87%E7%B2%BE%E9%80%89/"}]},{"title":"半监督学习   semi-supervisered","slug":"半监督学习","date":"2020-04-11T06:11:56.574Z","updated":"2020-04-13T01:34:14.558Z","comments":true,"path":"2020/04/11/半监督学习/","link":"","permalink":"http://coolwin8.github.io/2020/04/11/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"标注数据和未标注数据 直推 内部预测 归纳式 SSL 主动学习 机器先对未标注数据进行标注，人对机器不太确认的部分进行标注（p值），再把人标注数据放入训练集训练模型 SSL并非都有效 非标签数据加入可能不如加入少量标签数据； 假设满足 假设分布 同分布下同类样本距离更近 半监督趋势 边界 密度 聚类 自学习 self -learning 生成模型和判别模型 条件概率和联合概率 Multi-View Learning / Co-Learning 标签传递","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://coolwin8.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"半监督","slug":"半监督","permalink":"http://coolwin8.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3/"},{"name":"机器学习","slug":"机器学习","permalink":"http://coolwin8.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"通用流程","slug":"通用流程","date":"2020-04-11T06:11:56.567Z","updated":"2019-11-26T07:01:36.000Z","comments":true,"path":"2020/04/11/通用流程/","link":"","permalink":"http://coolwin8.github.io/2020/04/11/%E9%80%9A%E7%94%A8%E6%B5%81%E7%A8%8B/","excerpt":"","text":"机器学习业务通用流程1、数据清洗 缺失值 id 常数列 2、类型标准化 数值列 int32 float32 类别列 object 日期列 统一格式 输入： dict({dataDf / evalDf}) dict(params) 输出： Df 3、数据处理-缺失值处理 输入： Df1 Map（col: method) 输出： Df1 4、数据探查profile KS检验 检验两个数据集是否同分布（分别检验多种不同分布） 5、行缺失6、删除列（reference ） 输入： Df1 ，Df2(reference) 7、异常值处理 两种方式： u+3delta / 分位数+1.5倍 数据处理 拆分训练集、测试集 拆分数据类型： 时间、数值 时间变类别 连续便离散 拼表 类别列编码 应用连续到离散分箱器 应用连续到离散编码器 拼表 缺失率阈值计算 通过计算能力确定阈值，如以最终可用列数来约束 通过列缺失率分布来确定异常值的阈值，作为缺失率阈值 根据模型评估的结果来调整缺失率阈值，以确定保留的列 模型训练","categories":[],"tags":[]},{"title":"部署PyPi离线私有库","slug":"部署PyPi离线私有库","date":"2020-04-11T02:58:52.450Z","updated":"2020-04-13T01:34:54.401Z","comments":true,"path":"2020/04/11/部署PyPi离线私有库/","link":"","permalink":"http://coolwin8.github.io/2020/04/11/%E9%83%A8%E7%BD%B2PyPi%E7%A6%BB%E7%BA%BF%E7%A7%81%E6%9C%89%E5%BA%93/","excerpt":"","text":"1. 拉取镜像 pypiserver/pypiserver1docker pull pypiserver&#x2F;pypiserver:latest 2. docker 部署运行 运行container1234567891011mkdir -p &#x2F;data&#x2F;pypi&#x2F;packages# 无认证目录上传，直接将安装包下载到映射目录即可docker run --name pypiserver --restart&#x3D;always -d -p 8088:8080 -v &#x2F;data&#x2F;pypi&#x2F;packages:&#x2F;data&#x2F;packages pypiserver&#x2F;pypiserver:latest# apache认证pypiupload 上传htpasswd -sc &#x2F;data&#x2F;pypi&#x2F;auth&#x2F;.htpasswd lengweiln -sv &#x2F;usr&#x2F;local&#x2F;sbin&#x2F;python3.7&#x2F;bin&#x2F;pypiupload &#x2F;us&#x2F;bin&#x2F;pypiuploaddocker run --name pypiserver -d -p 8088:8080 -v &#x2F;data&#x2F;pypi&#x2F;auth&#x2F;.htpasswd:&#x2F;data&#x2F;.htpasswd pypiserver&#x2F;pypiserver:latest -P .htpasswd packages# 合成docker run --name pypiserver --restart&#x3D;always -d -p 8088:8080 -v &#x2F;data&#x2F;pypi&#x2F;auth&#x2F;.htpasswd:&#x2F;data&#x2F;.htpasswd -v &#x2F;data&#x2F;pypi&#x2F;packages&#x2F;:&#x2F;data&#x2F;packages&#x2F; pypiserver&#x2F;pypiserver:latest -P .htpasswd packages 3. 客户端配置 配置pypi 123456789[root@localhost pypi]# vi ~&#x2F;.pypirc [distutils]index-servers &#x3D; local[local]repository: http:&#x2F;&#x2F;192.168.1.14:8088username: lengweipassword: 123456 安装上传工具 pypi-upload 12[root@localhost]# pip install pypi-uploadpypiupload files &#x2F;data&#x2F;pypi&#x2F;packages&#x2F;* -i local 配置pip 12345678[root@localhost pypi]# vi ~&#x2F;.pip&#x2F;pip.conf[global]index-url &#x3D; http:&#x2F;&#x2F;192.168.1.14&#x2F;simpleextra-index-url&#x3D;https:&#x2F;&#x2F;pypi.mirrors.ustc.edu.cn&#x2F;simple# aliyun pypi镜像 https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple&#x2F;[install]trusted-host &#x3D; 192.168.1.14 4. 拉取依赖包到私有库 (在不同的平台下执行拉取，如win_amd64、manylinux等) Python 项目使用 pip 安装的包，都可以通过 pip freeze &gt;requirements.txt 导出环境中已有的模块。搭建 requirements.txt 离线 PyPI 仓库，我们首先需要把 requirements.txt 所有的模块安装包下载到本地。 1234567891011121314$ pip download -d &#x2F;data&#x2F;pypi&#x2F;packages -r requirements.txt --index-url https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple --extra-index-url https:&#x2F;&#x2F;wheels.galaxyproject.org&#x2F;simpleLooking in indexes: https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple, https:&#x2F;&#x2F;wheels.galaxyproject.org&#x2F;simpleCollecting amqp&#x3D;&#x3D;2.2.2 (from -r &#x2F;&#x2F;home&#x2F;shenweiyan&#x2F;galaxy&#x2F;requirements.txt (line 1))Downloading https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;packages&#x2F;88&#x2F;4a&#x2F;8c45a882d842678963516ebd9cf584a4ded51af719234c3b696c2e884c60&#x2F;amqp-2.2.2-py2.py3-none-any.whl (48kB) 100% |████████████████████████████████| 51kB 779kB&#x2F;sSaved .&#x2F;amqp-2.2.2-py2.py3-none-any.whl......Collecting wrapt&#x3D;&#x3D;1.10.11 (from -r &#x2F;home&#x2F;shenweiyan&#x2F;galaxy&#x2F;requirements.txt (line 134))Downloading https:&#x2F;&#x2F;wheels.galaxyproject.org&#x2F;packages&#x2F;wrapt-1.10.11-cp27-cp27mu-manylinux1_x86_64.whl (64kB) 100% |████████████████████████████████| 71kB 321kB&#x2F;sSaved &#x2F;home&#x2F;galaxy&#x2F;packages&#x2F;wrapt-1.10.11-cp27-cp27mu-manylinux1_x86_64.whlSuccessfully downloaded amqp appdirs asn1crypto babel bagit bcrypt bdbag beaker bioblend bleach boltons boto bunch bx-python bz2file certifi ...... wcwidth webencodings webob whoosh wrapt 把 /home/shenweiyan/packages 整个目录拷贝到目标服务器(可连网但速度极慢，目标路径：/data/galaxy-dist/packages)，搭建并启动 pypiserver，然后从本地离线 PyPI 仓库安装 requirements 软件 1$ pip install --index-url http:&#x2F;&#x2F;localhost:8080&#x2F;simple&#x2F; --extra-index-url https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple&#x2F; -r requirements.txt 5. 获取现有依赖库 pip导出安装的库到requirements.txt 1pip freeze &gt; requirements.txt pip导入requirements.txt中列出的库到系统 12pip install -r requirements.txtpip download -d &#x2F;data&#x2F;pypi&#x2F;packages -r requirements.txt pip download –only-binary=:all: –platform linux_x86_64 –python-version 3 –implementation cp –abi cp37m \\","categories":[{"name":"python","slug":"python","permalink":"http://coolwin8.github.io/categories/python/"},{"name":"pypi","slug":"python/pypi","permalink":"http://coolwin8.github.io/categories/python/pypi/"}],"tags":[{"name":"pypi","slug":"pypi","permalink":"http://coolwin8.github.io/tags/pypi/"},{"name":"部署","slug":"部署","permalink":"http://coolwin8.github.io/tags/%E9%83%A8%E7%BD%B2/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-03-26T06:30:10.543Z","updated":"2020-04-11T06:10:48.416Z","comments":true,"path":"2020/03/26/hello-world/","link":"","permalink":"http://coolwin8.github.io/2020/03/26/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"配置管理","slug":"配置管理","permalink":"http://coolwin8.github.io/categories/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"},{"name":"版本管理","slug":"配置管理/版本管理","permalink":"http://coolwin8.github.io/categories/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"},{"name":"Java生态","slug":"Java生态","permalink":"http://coolwin8.github.io/categories/Java%E7%94%9F%E6%80%81/"},{"name":"SprintBoot","slug":"Java生态/SprintBoot","permalink":"http://coolwin8.github.io/categories/Java%E7%94%9F%E6%80%81/SprintBoot/"},{"name":"系统应用 网络应用","slug":"系统应用-网络应用","permalink":"http://coolwin8.github.io/categories/%E7%B3%BB%E7%BB%9F%E5%BA%94%E7%94%A8-%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8/"},{"name":"GitHub","slug":"GitHub","permalink":"http://coolwin8.github.io/categories/GitHub/"},{"name":"k8s生态","slug":"k8s生态","permalink":"http://coolwin8.github.io/categories/k8s%E7%94%9F%E6%80%81/"},{"name":"k8s","slug":"k8s生态/k8s","permalink":"http://coolwin8.github.io/categories/k8s%E7%94%9F%E6%80%81/k8s/"},{"name":"java maven","slug":"java-maven","permalink":"http://coolwin8.github.io/categories/java-maven/"},{"name":"机器学习","slug":"机器学习","permalink":"http://coolwin8.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"python","slug":"python","permalink":"http://coolwin8.github.io/categories/python/"},{"name":"pypi","slug":"python/pypi","permalink":"http://coolwin8.github.io/categories/python/pypi/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://coolwin8.github.io/tags/gitlab/"},{"name":"配置管理","slug":"配置管理","permalink":"http://coolwin8.github.io/tags/%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"},{"name":"多模块","slug":"多模块","permalink":"http://coolwin8.github.io/tags/%E5%A4%9A%E6%A8%A1%E5%9D%97/"},{"name":"maven","slug":"maven","permalink":"http://coolwin8.github.io/tags/maven/"},{"name":"网络配置","slug":"网络配置","permalink":"http://coolwin8.github.io/tags/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"name":"VPN","slug":"VPN","permalink":"http://coolwin8.github.io/tags/VPN/"},{"name":"内网访问","slug":"内网访问","permalink":"http://coolwin8.github.io/tags/%E5%86%85%E7%BD%91%E8%AE%BF%E9%97%AE/"},{"name":"SSH","slug":"SSH","permalink":"http://coolwin8.github.io/tags/SSH/"},{"name":"kubectl","slug":"kubectl","permalink":"http://coolwin8.github.io/tags/kubectl/"},{"name":"命令参考","slug":"命令参考","permalink":"http://coolwin8.github.io/tags/%E5%91%BD%E4%BB%A4%E5%8F%82%E8%80%83/"},{"name":"docker","slug":"docker","permalink":"http://coolwin8.github.io/tags/docker/"},{"name":"DevOps","slug":"DevOps","permalink":"http://coolwin8.github.io/tags/DevOps/"},{"name":"nexus","slug":"nexus","permalink":"http://coolwin8.github.io/tags/nexus/"},{"name":"特征选择","slug":"特征选择","permalink":"http://coolwin8.github.io/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"},{"name":"网文精选","slug":"网文精选","permalink":"http://coolwin8.github.io/tags/%E7%BD%91%E6%96%87%E7%B2%BE%E9%80%89/"},{"name":"半监督","slug":"半监督","permalink":"http://coolwin8.github.io/tags/%E5%8D%8A%E7%9B%91%E7%9D%A3/"},{"name":"机器学习","slug":"机器学习","permalink":"http://coolwin8.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"pypi","slug":"pypi","permalink":"http://coolwin8.github.io/tags/pypi/"},{"name":"部署","slug":"部署","permalink":"http://coolwin8.github.io/tags/%E9%83%A8%E7%BD%B2/"}]}